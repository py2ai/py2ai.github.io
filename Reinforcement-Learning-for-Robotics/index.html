

  <!DOCTYPE html>
<html lang="en" itemscope itemtype="https://schema.org/Article">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Canonical URL - redirect www to non-www -->
  <link rel="canonical" href="https://pyshine.com/Reinforcement-Learning-for-Robotics/">

  <!-- Pinterest & Google verification -->
  <meta name="p:domain_verify" content="fb68a8459fe32b8b072bcd5cc620d125"/>
  <meta name="google-site-verification" content="WAkFPi5cvufClnQetgIl0STmvvwHhVf8jfyENFWhsxU" />
  <meta name="google-site-verification" content="g2pFZlv-92XQD67BPgiVHsvZ4TZH13Ucvmmvvv36kU4" />

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Reinforcement Learning for Robotics - Real-World Robot Control | PyShine</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Reinforcement Learning for Robotics - Real-World Robot Control" />
<meta name="author" content="PyShine Team" />
<meta property="og:locale" content="en" />
<meta name="description" content="Learn how Reinforcement Learning is revolutionizing robotics. Explore real-world robot control, sim-to-real transfer, and practical applications with code examples." />
<meta property="og:description" content="Learn how Reinforcement Learning is revolutionizing robotics. Explore real-world robot control, sim-to-real transfer, and practical applications with code examples." />
<link rel="canonical" href="https://pyshine.com/Reinforcement-Learning-for-Robotics/" />
<meta property="og:url" content="https://pyshine.com/Reinforcement-Learning-for-Robotics/" />
<meta property="og:site_name" content="PyShine" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-02-18T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Reinforcement Learning for Robotics - Real-World Robot Control" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"PyShine Team"},"dateModified":"2026-02-18T00:00:00+00:00","datePublished":"2026-02-18T00:00:00+00:00","description":"Learn how Reinforcement Learning is revolutionizing robotics. Explore real-world robot control, sim-to-real transfer, and practical applications with code examples.","headline":"Reinforcement Learning for Robotics - Real-World Robot Control","mainEntityOfPage":{"@type":"WebPage","@id":"https://pyshine.com/Reinforcement-Learning-for-Robotics/"},"name":"{{ page.title escape }}","url":"https://pyshine.com/Reinforcement-Learning-for-Robotics/"}</script>
<!-- End Jekyll SEO tag -->
  <!-- This will generate the canonical link automatically -->

  <script src="https://analytics.ahrefs.com/analytics.js" data-key="Im0K82YsmEDy08+6wyUIZA" async></script>

  <!-- Favicon & App Icons -->
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/img/icons/apple-touch-icon.png?v=qA3OXqyw77">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/icons/favicon-32x32.png?v=qA3OXqyw77">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/img/icons/favicon-16x16.png?v=qA3OXqyw77">
  <link rel="manifest" href="/assets/img/icons/manifest.json?v=qA3OXqyw77">
  <link rel="mask-icon" href="/assets/img/icons/safari-pinned-tab.svg?v=qA3OXqyw77" color="#5bbad5">
  <link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77">
  <!--[if IE]><link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77"><![endif]-->

  <!-- App & Theme Info -->
  <meta name="apple-mobile-web-app-title" content="Sleek">
  <meta name="application-name" content="Sleek">
  <meta name="msapplication-config" content="/assets/img/icons/browserconfig.xml?v=qA3OXqyw77">
  <meta name="theme-color" content="#ffffff">

  
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-TCVFBKF"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'GTM-TCVFBKF');
</script>

  

  <!-- Critical CSS Inline -->
  <style class="inlineCSS">
    h1{color:#313237;margin-top:0;margin-bottom:.5rem}.dark-bg{background-color:#19d319}@media (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:last-of-type,.post-card:nth-child(2n+2){margin-right:0}}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figure,main{display:block}figure{margin:1em 40px}a{background-color:transparent;-webkit-text-decoration-skip:objects}img{border-style:none}svg:not(:root){overflow:hidden}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}body{-webkit-overflow-scrolling:touch}*,::after,::before{-webkit-box-sizing:inherit;box-sizing:inherit}.site{display:-webkit-box;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.site__content{-webkit-box-flex:1;-ms-flex:1;flex:1}img{max-width:100%;height:auto;width:auto;vertical-align:middle}figure{margin:0}body{background-color:#fff;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Hiragino Sans GB","Microsoft YaHei","WenQuanYi Micro Hei",sans-serif;font-size:1rem;line-height:1.5;color:#343851;-webkit-font-smoothing:antialiased;-webkit-text-size-adjust:100%}p{margin-top:0;margin-bottom:1.25rem}h1,h2{color:#313237;margin-top:0;margin-bottom:.5rem}a{color:#277cea;text-decoration:none;border-bottom:1px dashed #277cea}.blur{background:#fff;filter:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg"><filter id="filter"><feGaussianBlur stdDeviation="16" /></filter></svg>#filter');-webkit-filter:blur(1rem);filter:blur(1rem)}.container{padding:0 20px}@media (min-width:0){.container{max-width:auto;margin:0 auto}}@media (min-width:36em){.container{max-width:540px;margin:0 auto}}@media (min-width:48em){.container{max-width:720px;margin:0 auto}}@media (min-width:62em){.container{max-width:960px;margin:0 auto}}@media (min-width:75em){.container{max-width:1170px;margin:0 auto}}.header{background-color:#fff;color:#343851;position:absolute;z-index:4;width:100%;top:0;left:0;will-change:transform;-webkit-transform:translateY(0);transform:translateY(0)}.header a{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-bottom:0}.header__logo{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;overflow:hidden;padding:19px 0;margin-right:1.25rem;outline:0;border-bottom:0;color:#313237}.header__logo .header__logo--container{width:58px}.header__logo .header__logo--container .logo{fill:currentColor}.header__inner{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:3.75em;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.header__links{padding-bottom:.5rem;display:none;position:absolute;top:3.75em;left:0;width:100%;height:auto;background:#fff}.header__link{color:#343851;padding:.938rem 0;border-top:1px solid #ededed}.header__toggle{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;width:44px;height:100%;background-color:transparent;padding-left:1.25rem}.header__toggle span{display:block;position:relative;margin-top:4px;background-color:#343851;width:100%;height:2px;border-radius:1px}.header__toggle span:first-child{margin-top:0}@media (min-width:62em){.header__toggle{display:none;visibility:hidden}.header__links{position:static;padding:0;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;visibility:visible;width:auto;height:100%}.header__links-wrapper{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;padding:0}.header__link{position:relative;padding:.938rem 1rem;border:0;height:100%}.header__link::after{content:"";display:block;position:absolute;left:0;bottom:0;height:3px;width:100%;-webkit-transform:scaleX(0);transform:scaleX(0);background:#277cea}}.post-card{display:block;position:relative;width:100%;min-height:250px;border-radius:4px;overflow:hidden;background-color:#fff;-webkit-box-shadow:0 1px 3px rgba(0,0,0,.08);box-shadow:0 1px 3px rgba(0,0,0,.08);margin-bottom:2.25rem;border-bottom:0}@media (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:0}}@media (min-width:75em){.post-card{width:31.25%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:3.125%}}.post-card__label{position:absolute;top:1.5rem;left:1.5rem;z-index:2}.post-card__thumb{margin:0;background:#fff;position:relative;overflow:hidden}.post-card__thumb::after{content:"";display:block;height:0;width:100%;padding-bottom:56.25%}.post-card__thumb>*{position:absolute;top:0;left:0;width:100%;height:100%;display:block}.post-card__inner{padding:1.875rem 1.25rem .625rem;color:#838c8d}.post-card__header{margin-bottom:.75rem}.post-card__header .post-card__meta{font-size:.875rem}.label{padding:0 10px;margin-bottom:1rem;display:inline-block;line-height:20px;font-size:.75rem;text-transform:uppercase;letter-spacing:1px;color:rgba(255,255,255,.8);border:2px solid rgba(255,255,255,.5);border-radius:100px}.hero{margin:3.75rem auto 0;min-height:16.25rem;width:100%;position:relative;background-color:#dde5ea;background-repeat:no-repeat;background-position:50%;background-size:cover}@media (min-width:62em){.hero{margin:0 auto;height:36em}}.hero::before{position:absolute;display:block;content:"";top:0;left:0;width:100%;height:100%;background:rgba(52,56,81,.8)}.hero__wrap{position:absolute;margin:auto;top:50%;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);text-align:center;color:rgba(255,255,255,.8);width:100%;max-width:90%;z-index:1}.hero__wrap .hero__title{font-size:1.8em;color:#fff}.blog{background-color:#f9f9f9}.post-list{padding-top:2.5em;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-flex:1;-ms-flex:1 0 auto;flex:1 0 auto}@media (min-width:48em){.hero__wrap{max-width:40em}.hero__wrap .hero__title{padding:1rem 0;font-size:2.625em;line-height:3.125rem}.post-list{padding-top:5em}}
  </style>

  <!-- Main CSS -->
  <link rel="preload" href="/assets/css/main.css" as="style" onload="this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="/assets/css/main.css"></noscript>

  <script type="text/javascript">
    /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
(function(w){"use strict";if(!w.loadCSS){w.loadCSS=function(){}}
var rp=loadCSS.relpreload={};rp.support=(function(){var ret;try{ret=w.document.createElement("link").relList.supports("preload")}catch(e){ret=!1}
return function(){return ret}})();rp.bindMediaToggle=function(link){var finalMedia=link.media||"all";function enableStylesheet(){link.media=finalMedia}
if(link.addEventListener){link.addEventListener("load",enableStylesheet)}else if(link.attachEvent){link.attachEvent("onload",enableStylesheet)}
setTimeout(function(){link.rel="stylesheet";link.media="only x"});setTimeout(enableStylesheet,3000)};rp.poly=function(){if(rp.support()){return}
var links=w.document.getElementsByTagName("link");for(var i=0;i<links.length;i++){var link=links[i];if(link.rel==="preload"&&link.getAttribute("as")==="style"&&!link.getAttribute("data-loadcss")){link.setAttribute("data-loadcss",!0);rp.bindMediaToggle(link)}}};if(!rp.support()){rp.poly();var run=w.setInterval(rp.poly,500);if(w.addEventListener){w.addEventListener("load",function(){rp.poly();w.clearInterval(run)})}else if(w.attachEvent){w.attachEvent("onload",function(){rp.poly();w.clearInterval(run)})}}
if(typeof exports!=="undefined"){exports.loadCSS=loadCSS}
else{w.loadCSS=loadCSS}}(typeof global!=="undefined"?global:this))

  </script>

  <!-- MathJax -->
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>


  <body class="site" itemscope itemtype="https://schema.org/WebPage">

    
      <!-- Google Tag Manager (noscript) -->
      <noscript>
        <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TCVFBKF"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
      </noscript>
      <!-- End Google Tag Manager -->
    

    <header class="header"
  itemscope
  itemtype="http://schema.org/SiteNavigationElement"
  aria-label="Main navigation">

  <div class="container">
    <div class="header__inner">

      <!-- Logo -->
      <a class="header__logo" href="/">
        <div class="header__logo--container">
          <?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 16.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24" xml:space="preserve">
<g>
	<path d="M18.121,9.88l-7.832-7.836c-0.155-0.158-0.428-0.155-0.584,0L1.842,9.913c-0.262,0.263-0.073,0.705,0.292,0.705h2.069v7.042c0,0.227,0.187,0.414,0.414,0.414h3.725c0.228,0,0.414-0.188,0.414-0.414v-3.313h2.483v3.313c0,0.227,0.187,0.414,0.413,0.414h3.726c0.229,0,0.414-0.188,0.414-0.414v-7.042h2.068h0.004C18.331,10.617,18.389,10.146,18.121,9.88 M14.963,17.245h-2.896v-3.313c0-0.229-0.186-0.415-0.414-0.415H8.342c-0.228,0-0.414,0.187-0.414,0.415v3.313H5.032v-6.628h9.931V17.245z M3.133,9.79l6.864-6.868l6.867,6.868H3.133z"></path>

	
	
</g>
</svg>

        </div>
      </a>

      <!-- Navigation -->
      <nav class="header__links">
        <div class="header__links-wrapper">

          
            
              <a class="header__link" href="/">
                Home
              </a>
            
          
            
              <a class="header__link" href="/categories">
                Posts
              </a>
            
          
            

            <!-- Applications Dropdown -->
            <div class="header__dropdown">
              <span class="header__link header__dropdown-toggle">
                Applications
                <span class="dropdown-arrow">â–¾</span>
              </span>

              <div class="header__dropdown-menu">
                
                  <a class="header__dropdown-item"
                     href="/photo_correction">
                    Online Photo Correction
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/photo">
                    Online Passport Photo 20KB
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/finger.html">
                    Online Fingers Scanner
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/avatars">
                    Online Make Avatars
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/kanban/debounce.html">
                    Online Reminder App
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/converter.html">
                    Online Image Resize
                  </a>
                
              </div>
            </div>

            
          
            

            <!-- Applications Dropdown -->
            <div class="header__dropdown">
              <span class="header__link header__dropdown-toggle">
                Games
                <span class="dropdown-arrow">â–¾</span>
              </span>

              <div class="header__dropdown-menu">
                
                  <a class="header__dropdown-item"
                     href="/games/snake">
                    Snake Game
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/flappy-bird">
                    Flappy Bird
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/tetris">
                    Tetris
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/memory-match">
                    Memory Match
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/pong">
                    Pong
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/2048">
                    2048
                  </a>
                
              </div>
            </div>

            
          
            
              <a class="header__link" href="/about">
                About
              </a>
            
          
            
              <a class="header__link" href="/contact">
                Contact
              </a>
            
          
            
              <a class="header__link" href="/privacy">
                Privacy Policy
              </a>
            
          
            
              <a class="header__link" href="/disclaimer">
                Disclaimer
              </a>
            
          

        </div>
      </nav>

      <!-- Language Switcher -->
      

      <!-- Mobile Toggle -->
      <div class="header__toggle">
        <span></span><span></span><span></span>
      </div>

    </div>
  </div>

<style>
/* ==================================================
   ðŸ”’ HEADER â€” ALWAYS VISIBLE, FULL WIDTH COLOR
================================================== */
.header{
  position: fixed;
  top: 0;
  left: 0;
  width: 100vw;           /* full width */
  z-index: 10000;
  background: #FFFFFF;    /* uniform header background */
  box-shadow: 0 2px 12px rgba(0,0,0,.35);
  transform: none !important;
  transition: none !important;
}

/* Lock height to avoid reflow */
.header__inner{
  min-height: 72px;
  display: flex;
  align-items: center;
  justify-content: space-between;
}

/* Prevent content hiding under fixed header */
body{
  padding-top: 72px;
}

/* ===============================
   NAV BASE
=============================== */
.header__links-wrapper{
  display:flex;
  align-items:center;
  gap:1.5rem;
}

.header__link,
.header__dropdown-toggle{
  display:inline-flex;
  align-items:center;
  gap:6px;
  cursor:pointer;
  font-size:16px;
  font-weight:500;
  color:#000000;
}

/* ===============================
   DROPDOWN
=============================== */
.header__dropdown{
  position:relative;
}

.dropdown-arrow{
  font-size:1.4em;
  transition:transform .2s ease;
}

.header__dropdown:hover .dropdown-arrow{
  transform:rotate(180deg);
}

.header__dropdown-menu{
  position:absolute;
  top:100%;
  left:0;
  min-width:220px;
  background:#121212;
  border:1px solid #333;
  border-radius:10px;
  padding:6px 0;
  display:none;
  z-index:9999;
}

.header__dropdown:hover .header__dropdown-menu{
  display:block;
}

.header__dropdown-item{
  display:block;
  padding:10px 16px;
  color:#eaeaea;
  text-decoration:none;
}

.header__dropdown-item:hover{
  background:#1f1f1f;
}

/* ===============================
   MOBILE
=============================== */
@media (max-width:768px){

  body{
    padding-top: 64px;
  }

  .header__inner{
    min-height: 64px;
  }

  .header__links-wrapper{
    flex-direction:column;
    align-items:stretch;
    gap:0;
  }

  .header__dropdown-toggle{
    justify-content:space-between;
    padding:14px 16px;
  }

  .header__dropdown-menu{
    position:static;
    display:none;
    background:#0f0f0f;
    border:none;
  }

  .header__dropdown:hover .header__dropdown-menu{
    display:block;
  }

  .header__dropdown-item{
    padding:14px 20px;
    background:#1a1a1a;
    border-top:1px solid #2a2a2a;
    font-size:15px;
  }
}

/* ===============================
   LANGUAGE SWITCHER
=============================== */
.header__lang-switcher{
  display:inline-flex;
  gap:.5rem;
  align-items:center;
  font-size:1.3rem;
  margin-left:1rem;
}
.lang-flag.active{ text-decoration:underline }
.lang-flag.disabled{ opacity:.5; filter:grayscale(100%) }

</style>
</header>


    
      <div class="hero lazyload"
           data-bg="https://pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl.jpg"
           role="img"
           aria-label="Reinforcement Learning for Robotics - Real-World Robot Control">
    
        <div class="hero__wrap">

          
            <div class="hero__categories">
              
                <a class="label"
                   href="/categories/#Machine Learning"
                   aria-label="Category: Machine Learning">
                   Machine Learning
                </a>
                &nbsp;
              
                <a class="label"
                   href="/categories/#AI"
                   aria-label="Category: AI">
                   AI
                </a>
                &nbsp;
              
                <a class="label"
                   href="/categories/#Python"
                   aria-label="Category: Python">
                   Python
                </a>
                &nbsp;
              
                <a class="label"
                   href="/categories/#Robotics"
                   aria-label="Category: Robotics">
                   Robotics
                </a>
                &nbsp;
              
                <a class="label"
                   href="/categories/#Deep RL"
                   aria-label="Category: Deep RL">
                   Deep RL
                </a>
                
              
            </div>
          

          <h1 class="hero__title" itemprop="headline">Reinforcement Learning for Robotics - Real-World Robot Control</h1>

          <p class="hero__meta">
            <time datetime="2026-02-18T00:00:00+00:00" itemprop="datePublished">
              18 Feb 2026
            </time>
            &nbsp;Â·&nbsp;
            
            <span itemprop="timeRequired">
              
                51 mins read
              
            </span>
          </p>
        </div>
      </div>

    <main class="site__content" role="main">

      <!-- âœ… START: YouTube Video Section -->
      <section id="youtube-video" style="text-align:center; padding:5px 5px; background:#f8f8f8;">
        <div class="container">
          <div style="margin-top:25px;">
            <a href="https://www.youtube.com/@pyshine_official/shorts"
              target="_blank"
              style="background:#ff0000; color:white; padding:12px 24px; border-radius:6px; text-decoration:none; font-weight:bold; display:inline-flex; align-items:center; gap:8px;">
              <svg xmlns="http://www.w3.org/2000/svg" width="22" height="16" viewBox="0 0 24 24">
                <path fill="#FFF" d="M23.5 6.2a3 3 0 0 0-2.1-2.1C19.5 3.5 12 3.5 12 3.5s-7.5 0-9.4.6A3 3 0 0 0 .5 6.2 31.5 31.5 0 0 0 0 12a31.5 31.5 0 0 0 .5 5.8 3 3 0 0 0 2.1 2.1c1.9.6 9.4.6 9.4.6s7.5 0 9.4-.6a3 3 0 0 0 2.1-2.1A31.5 31.5 0 0 0 24 12a31.5 31.5 0 0 0-.5-5.8z"/>
                <path fill="#FF0000" d="M9.75 15.02v-6l6 3z"/>
              </svg>
              Watch PyShine on YouTube
            </a>
          </div>
        </div>
      </section>

      <!-- âœ… END: YouTube Video Section -->

      <div class="container post-layout">

        <!-- SIDEBAR TOC -->
        <aside class="post-toc" id="post-toc">
          <h3 class="no-toc">Contents</h3>
          <nav id="toc-list"></nav>
        </aside>

        <!-- MAIN CONTENT -->
        <article class="post-content"
                 itemprop="articleBody"
                 itemscope itemtype="https://schema.org/Article">

          <!-- INLINE TOC -->
          <div id="inline-toc" class="inline-toc-box">
            <h3 class="no-toc">Contents</h3>
            <nav id="inline-toc-list"></nav>
          </div>

          <h1 id="reinforcement-learning-for-robotics---real-world-robot-control">Reinforcement Learning for Robotics - Real-World Robot Control</h1>

<p>Welcome to our comprehensive guide on <strong>Reinforcement Learning for Robotics</strong>! In this post, weâ€™ll explore how RL is transforming robotics, enabling robots to learn complex tasks through interaction with their environment. Weâ€™ll cover the unique challenges of applying RL to real-world robots, sim-to-real transfer techniques, and practical implementations.</p>

<h2 id="introduction-rl-in-robotics">Introduction: RL in Robotics</h2>

<p>Reinforcement Learning has emerged as a powerful paradigm for robot control, enabling robots to learn complex behaviors through trial and error. Unlike traditional control methods that require precise mathematical models, RL allows robots to learn from experience, making them more adaptable and capable in dynamic environments.</p>

<h3 id="why-rl-for-robotics">Why RL for Robotics?</h3>

<p><strong>Adaptability:</strong></p>

<ul>
  <li>Robots can adapt to changing environments</li>
  <li>No need for perfect mathematical models</li>
  <li>Learn from experience and improve over time</li>
  <li>Handle uncertainty and noise naturally</li>
</ul>

<p><strong>Complex Tasks:</strong></p>

<ul>
  <li>Learn behaviors that are hard to program manually</li>
  <li>Master high-dimensional control problems</li>
  <li>Optimize long-term objectives</li>
  <li>Discover novel strategies</li>
</ul>

<p><strong>Generalization:</strong></p>

<ul>
  <li>Transfer skills across different scenarios</li>
  <li>Learn from demonstrations</li>
  <li>Handle unseen situations</li>
  <li>Robust to variations</li>
</ul>

<h2 id="challenges-in-robot-rl">Challenges in Robot RL</h2>

<p>Applying RL to real robots presents unique challenges that donâ€™t exist in simulation:</p>

<h3 id="1-sample-efficiency">1. Sample Efficiency</h3>

<p>Real robots have limited time and resources:</p>

<ul>
  <li><strong>Time constraints:</strong> Real-world experiments take time</li>
  <li><strong>Wear and tear:</strong> Physical components degrade</li>
  <li><strong>Energy costs:</strong> Operating robots is expensive</li>
  <li><strong>Safety concerns:</strong> Learning can be dangerous</li>
</ul>

<p><strong>Solution:</strong> Use simulation for most training, then transfer to real robot.</p>

<h3 id="2-safety-and-risk">2. Safety and Risk</h3>

<p>Learning on real robots involves risk:</p>

<ul>
  <li><strong>Physical damage:</strong> Robots can break during learning</li>
  <li><strong>Human safety:</strong> Learning behaviors might be unpredictable</li>
  <li><strong>Environment damage:</strong> Robots can damage surroundings</li>
  <li><strong>Irreversible actions:</strong> Some actions canâ€™t be undone</li>
</ul>

<p><strong>Solution:</strong> Use safe exploration, constrained policies, and simulation.</p>

<h3 id="3-reality-gap">3. Reality Gap</h3>

<p>Simulation never perfectly matches reality:</p>

<ul>
  <li><strong>Physics differences:</strong> Simulators are approximations</li>
  <li><strong>Sensor noise:</strong> Real sensors are noisier</li>
  <li><strong>Actuator delays:</strong> Real motors have delays</li>
  <li><strong>Friction and wear:</strong> Real-world physics is complex</li>
</ul>

<p><strong>Solution:</strong> Domain randomization, system identification, and adaptive methods.</p>

<h3 id="4-partial-observability">4. Partial Observability</h3>

<p>Real robots have limited perception:</p>

<ul>
  <li><strong>Sensor limitations:</strong> Canâ€™t see everything</li>
  <li><strong>Occlusions:</strong> Objects block views</li>
  <li><strong>Noise:</strong> Sensors have errors</li>
  <li><strong>Latency:</strong> Information arrives with delay</li>
</ul>

<p><strong>Solution:</strong> Use recurrent networks, state estimation, and robust policies.</p>

<h2 id="sim-to-real-transfer">Sim-to-Real Transfer</h2>

<p>The most common approach to robot RL is training in simulation and transferring to reality:</p>

<h3 id="domain-randomization">Domain Randomization</h3>

<p>Randomize simulation parameters to make policies robust:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="k">class</span> <span class="nc">RandomizedRobotEnv</span><span class="p">(</span><span class="n">gym</span><span class="p">.</span><span class="n">Env</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Randomize physical parameters
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">friction</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mass</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">damping</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
      
        <span class="c1"># Randomize visual appearance
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">lighting</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">texture</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">([</span><span class="s">'wood'</span><span class="p">,</span> <span class="s">'metal'</span><span class="p">,</span> <span class="s">'plastic'</span><span class="p">])</span>
      
        <span class="c1"># Randomize sensor noise
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">sensor_noise</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
      
        <span class="c1"># Randomize delays
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">action_delay</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span> <span class="o">=</span> <span class="p">[]</span>
      
        <span class="c1"># State and action dimensions
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">state_dim</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_dim</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">state_dim</span><span class="p">)</span>
      
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Re-randomize each episode
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">friction</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mass</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">state_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_observation</span><span class="p">()</span>
  
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Apply action with delay
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">actual_action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">action_delay</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_delay</span> <span class="k">else</span> <span class="n">action</span>
      
        <span class="c1"># Add sensor noise
</span>        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_observation</span><span class="p">()</span>
        <span class="n">noisy_obs</span> <span class="o">=</span> <span class="n">obs</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">sensor_noise</span><span class="p">,</span> <span class="n">obs</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
      
        <span class="c1"># Apply physics with randomization
</span>        <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">apply_physics</span><span class="p">(</span><span class="n">actual_action</span><span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">compute_reward</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
        <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_done</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">noisy_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="p">{}</span>
  
    <span class="k">def</span> <span class="nf">get_observation</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">current_state</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
  
    <span class="k">def</span> <span class="nf">apply_physics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Simplified physics simulation
</span>        <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">current_state</span> <span class="o">+</span> <span class="n">action</span> <span class="o">*</span> <span class="mf">0.1</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span>
        <span class="k">return</span> <span class="n">next_state</span>
  
    <span class="k">def</span> <span class="nf">compute_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Simplified reward computation
</span>        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">is_done</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Simplified termination condition
</span>        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">9.0</span>
</code></pre></div></div>

<h3 id="system-identification">System Identification</h3>

<p>Learn the difference between simulation and reality:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">DynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
        <span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">state</span> <span class="o">+</span> <span class="n">delta</span>

<span class="k">def</span> <span class="nf">train_dynamics_model</span><span class="p">(</span><span class="n">real_data</span><span class="p">):</span>
    <span class="s">"""
    Train dynamics model on real robot data
    real_data: list of (state, action, next_state) tuples
    """</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
  
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">next_state</span> <span class="ow">in</span> <span class="n">real_data</span><span class="p">:</span>
            <span class="n">pred_next</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred_next</span><span class="p">,</span> <span class="n">next_state</span><span class="p">)</span>
          
            <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
  
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">adapt_policy_to_real</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">dynamics_model</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="s">"""
    Adapt policy using learned dynamics model
    """</span>
    <span class="n">adapted_policy</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">adapted_policy</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
  
    <span class="c1"># Fine-tune policy on learned dynamics
</span>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">adapted_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">pred_next</span> <span class="o">=</span> <span class="n">dynamics_model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
      
        <span class="c1"># Optimize policy for learned dynamics (simplified value function)
</span>        <span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pred_next</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">value</span>
      
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
  
    <span class="k">return</span> <span class="n">adapted_policy</span>
</code></pre></div></div>

<h3 id="domain-adaptation">Domain Adaptation</h3>

<p>Adapt policies to real-world domain:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DomainAdaptation</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sim_policy</span><span class="p">,</span> <span class="n">real_env</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">sim_policy</span> <span class="o">=</span> <span class="n">sim_policy</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">real_env</span> <span class="o">=</span> <span class="n">real_env</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">real_policy</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">sim_policy</span><span class="p">)</span>
      
    <span class="k">def</span> <span class="nf">adapt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_episodes</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="s">"""
        Adapt policy to real environment
        """</span>
        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_episodes</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">real_env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">episode_data</span> <span class="o">=</span> <span class="p">[]</span>
          
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
                <span class="c1"># Get action from adapted policy
</span>                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">real_policy</span><span class="p">.</span><span class="n">get_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
              
                <span class="c1"># Execute on real robot
</span>                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">real_env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">episode_data</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">))</span>
              
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                    <span class="k">break</span>
          
            <span class="c1"># Update policy using real data
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">update_policy</span><span class="p">(</span><span class="n">episode_data</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">update_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">episode_data</span><span class="p">):</span>
        <span class="s">"""
        Update policy using real-world experience
        """</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">real_policy</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
      
        <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span> <span class="ow">in</span> <span class="n">episode_data</span><span class="p">:</span>
            <span class="c1"># Compute target using real rewards (simplified)
</span>            <span class="n">target</span> <span class="o">=</span> <span class="n">reward</span>
          
            <span class="c1"># Get predicted action
</span>            <span class="n">pred_action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">real_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
          
            <span class="c1"># Update policy
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">pred_action</span> <span class="o">-</span> <span class="n">action</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
          
            <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="practical-robot-rl-applications">Practical Robot RL Applications</h2>

<h3 id="1-robotic-manipulation">1. Robotic Manipulation</h3>

<p>Learning to grasp and manipulate objects:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>

<span class="k">class</span> <span class="nc">GraspingEnv</span><span class="p">(</span><span class="n">gym</span><span class="p">.</span><span class="n">Env</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Robot arm with gripper
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">arm_joints</span> <span class="o">=</span> <span class="mi">7</span>  <span class="c1"># 7-DOF arm
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">gripper_joints</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># 2-DOF gripper
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">action_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">arm_joints</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">gripper_joints</span>
      
        <span class="c1"># State space
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">state_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">arm_joints</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">gripper_joints</span> <span class="o">+</span> <span class="mi">6</span>  <span class="c1"># +6 for object pose
</span>      
        <span class="c1"># Workspace limits
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">workspace</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'x'</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
            <span class="s">'y'</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
            <span class="s">'z'</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="p">}</span>
      
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Randomize object position
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">object_pos</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span>
            <span class="n">low</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
            <span class="n">high</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
        <span class="p">)</span>
      
        <span class="c1"># Reset arm to home position
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">arm_pos</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">arm_joints</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gripper_pos</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">])</span>  <span class="c1"># Open gripper
</span>      
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">()</span>
  
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Execute action
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">arm_pos</span> <span class="o">=</span> <span class="n">action</span><span class="p">[:</span><span class="bp">self</span><span class="p">.</span><span class="n">arm_joints</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gripper_pos</span> <span class="o">=</span> <span class="n">action</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">arm_joints</span><span class="p">:]</span>
      
        <span class="c1"># Get end-effector position
</span>        <span class="n">ee_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward_kinematics</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">arm_pos</span><span class="p">)</span>
      
        <span class="c1"># Compute reward
</span>        <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">ee_pos</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">object_pos</span><span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="o">-</span><span class="n">distance</span>
      
        <span class="c1"># Check if grasped
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">check_grasp</span><span class="p">():</span>
            <span class="n">reward</span> <span class="o">+=</span> <span class="mf">10.0</span>
      
        <span class="c1"># Check if lifted
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">check_lift</span><span class="p">():</span>
            <span class="n">reward</span> <span class="o">+=</span> <span class="mf">20.0</span>
      
        <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">check_lift</span><span class="p">()</span> <span class="ow">or</span> <span class="n">distance</span> <span class="o">&gt;</span> <span class="mf">1.0</span>
      
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">(),</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="p">{}</span>
  
    <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">arm_pos</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">gripper_pos</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">object_pos</span>
        <span class="p">])</span>
  
    <span class="k">def</span> <span class="nf">forward_kinematics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">joint_positions</span><span class="p">):</span>
        <span class="c1"># Simplified forward kinematics
</span>        <span class="c1"># In practice, use robot-specific kinematics
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">joint_positions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">joint_positions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">joint_positions</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">])</span>
  
    <span class="k">def</span> <span class="nf">check_grasp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Check if gripper is closed around object
</span>        <span class="n">gripper_closed</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">gripper_pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.01</span>
        <span class="n">near_object</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">forward_kinematics</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">arm_pos</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">object_pos</span>
        <span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.05</span>
        <span class="k">return</span> <span class="n">gripper_closed</span> <span class="ow">and</span> <span class="n">near_object</span>
  
    <span class="k">def</span> <span class="nf">check_lift</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Check if object is lifted above table
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">object_pos</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.1</span>

<span class="c1"># Train grasping policy
</span><span class="n">env</span> <span class="o">=</span> <span class="n">GraspingEnv</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s">'MlpPolicy'</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>

<span class="c1"># Save policy
</span><span class="n">model</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">'grasping_policy'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-mobile-robot-navigation">2. Mobile Robot Navigation</h3>

<p>Learning to navigate complex environments:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">NavigationPolicy</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
      
        <span class="c1"># Encoder for sensor data
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
      
        <span class="c1"># Policy head
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">policy_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>
      
        <span class="c1"># Value head
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">value_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">value_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">value</span>
  
    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Convert to tensor if needed
</span>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
          
            <span class="n">action</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">action</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">NavigationEnv</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Mobile robot state
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">theta</span> <span class="o">=</span> <span class="mf">0.0</span>
      
        <span class="c1"># Goal position
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">goal_x</span> <span class="o">=</span> <span class="mf">5.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">goal_y</span> <span class="o">=</span> <span class="mf">5.0</span>
      
        <span class="c1"># Obstacles
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">obstacles</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s">'x'</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span> <span class="s">'y'</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span> <span class="s">'r'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'x'</span><span class="p">:</span> <span class="mf">3.0</span><span class="p">,</span> <span class="s">'y'</span><span class="p">:</span> <span class="mf">4.0</span><span class="p">,</span> <span class="s">'r'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'x'</span><span class="p">:</span> <span class="mf">4.0</span><span class="p">,</span> <span class="s">'y'</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s">'r'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}</span>
        <span class="p">]</span>
      
        <span class="c1"># Lidar sensor
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">lidar_ranges</span> <span class="o">=</span> <span class="mi">36</span>  <span class="c1"># 360 degrees, 10 degree resolution
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">max_range</span> <span class="o">=</span> <span class="mf">3.0</span>
      
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">theta</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">()</span>
  
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Action: [linear_velocity, angular_velocity]
</span>        <span class="n">v</span><span class="p">,</span> <span class="n">omega</span> <span class="o">=</span> <span class="n">action</span>
      
        <span class="c1"># Update position (simple kinematics)
</span>        <span class="n">dt</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="n">dt</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="n">dt</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">theta</span> <span class="o">+=</span> <span class="n">omega</span> <span class="o">*</span> <span class="n">dt</span>
      
        <span class="c1"># Get lidar readings
</span>        <span class="n">lidar</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_lidar</span><span class="p">()</span>
      
        <span class="c1"># Compute reward
</span>        <span class="n">distance_to_goal</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">goal_x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">goal_y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="o">-</span><span class="n">distance_to_goal</span>
      
        <span class="c1"># Penalty for obstacles
</span>        <span class="n">min_distance</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">lidar</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">min_distance</span> <span class="o">&lt;</span> <span class="mf">0.3</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">-=</span> <span class="mf">10.0</span>
      
        <span class="c1"># Bonus for reaching goal
</span>        <span class="k">if</span> <span class="n">distance_to_goal</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">+=</span> <span class="mf">100.0</span>
      
        <span class="n">done</span> <span class="o">=</span> <span class="n">distance_to_goal</span> <span class="o">&lt;</span> <span class="mf">0.1</span> <span class="ow">or</span> <span class="n">min_distance</span> <span class="o">&lt;</span> <span class="mf">0.1</span>
      
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="p">{}</span>
  
    <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">lidar</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_lidar</span><span class="p">()</span>
        <span class="n">goal_angle</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arctan2</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">goal_y</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">goal_x</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span>
        <span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">theta</span>
      
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span>
            <span class="n">lidar</span><span class="p">,</span>
            <span class="p">[</span><span class="n">goal_angle</span><span class="p">]</span>
        <span class="p">])</span>
  
    <span class="k">def</span> <span class="nf">get_lidar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">ranges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lidar_ranges</span><span class="p">):</span>
            <span class="n">angle</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">theta</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">lidar_ranges</span><span class="p">)</span>
          
            <span class="c1"># Check intersection with obstacles
</span>            <span class="n">min_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_range</span>
            <span class="k">for</span> <span class="n">obs</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">obstacles</span><span class="p">:</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">ray_cast</span><span class="p">(</span><span class="n">angle</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">dist</span> <span class="o">&lt;</span> <span class="n">min_dist</span><span class="p">:</span>
                    <span class="n">min_dist</span> <span class="o">=</span> <span class="n">dist</span>
          
            <span class="n">ranges</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">min_dist</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">ranges</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">ray_cast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">angle</span><span class="p">,</span> <span class="n">obstacle</span><span class="p">):</span>
        <span class="c1"># Simplified ray casting
</span>        <span class="n">dx</span> <span class="o">=</span> <span class="n">obstacle</span><span class="p">[</span><span class="s">'x'</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span>
        <span class="n">dy</span> <span class="o">=</span> <span class="n">obstacle</span><span class="p">[</span><span class="s">'y'</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dx</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">dy</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">obstacle</span><span class="p">[</span><span class="s">'r'</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="3-walking-robots">3. Walking Robots</h3>

<p>Learning locomotion for legged robots:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">WalkingPolicy</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
      
        <span class="c1"># Recurrent network for temporal dependencies
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      
        <span class="c1"># Policy network
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>
      
        <span class="c1"># Value network
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
      
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">value</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
      
        <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">hidden</span>
  
    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Convert to tensor if needed
</span>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
          
            <span class="n">action</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">new_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">action</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">new_hidden</span>

<span class="k">class</span> <span class="nc">WalkingEnv</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># 4-legged robot (quadruped)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">num_legs</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">joints_per_leg</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_legs</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">joints_per_leg</span>
      
        <span class="c1"># State space
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">state_dim</span> <span class="o">=</span> <span class="mi">24</span>  <span class="c1"># Joint angles + velocities + body orientation
</span>      
        <span class="c1"># Robot parameters
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">body_mass</span> <span class="o">=</span> <span class="mf">10.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">leg_length</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_torque</span> <span class="o">=</span> <span class="mf">20.0</span>
      
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Initialize robot in standing position
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">joint_angles</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">action_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">joint_velocities</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">action_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">body_orientation</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>  <span class="c1"># Roll, pitch, yaw
</span>      
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">()</span>
  
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Apply torques to joints
</span>        <span class="n">torques</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">action</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_torque</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">max_torque</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_torque</span><span class="p">)</span>
      
        <span class="c1"># Simulate dynamics (simplified)
</span>        <span class="n">dt</span> <span class="o">=</span> <span class="mf">0.01</span>
      
        <span class="c1"># Update joint velocities
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">joint_velocities</span> <span class="o">+=</span> <span class="n">torques</span> <span class="o">*</span> <span class="n">dt</span>
      
        <span class="c1"># Update joint angles
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">joint_angles</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">joint_velocities</span> <span class="o">*</span> <span class="n">dt</span>
      
        <span class="c1"># Compute forward velocity
</span>        <span class="n">forward_velocity</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">compute_forward_velocity</span><span class="p">()</span>
      
        <span class="c1"># Compute reward
</span>        <span class="n">reward</span> <span class="o">=</span> <span class="n">forward_velocity</span>
      
        <span class="c1"># Penalty for falling
</span>        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">body_orientation</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">body_orientation</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">-=</span> <span class="mf">10.0</span>
      
        <span class="c1"># Penalty for energy
</span>        <span class="n">reward</span> <span class="o">-=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">torques</span><span class="p">))</span>
      
        <span class="n">done</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">body_orientation</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">0.8</span> <span class="ow">or</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">body_orientation</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">0.8</span>
      
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">(),</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="p">{}</span>
  
    <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">joint_angles</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">joint_velocities</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">body_orientation</span>
        <span class="p">])</span>
  
    <span class="k">def</span> <span class="nf">compute_forward_velocity</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Simplified forward velocity computation
</span>        <span class="c1"># In practice, use proper kinematics
</span>        <span class="n">avg_leg_velocity</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">joint_velocities</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">avg_leg_velocity</span> <span class="o">*</span> <span class="mf">0.5</span>
</code></pre></div></div>

<h2 id="advanced-techniques">Advanced Techniques</h2>

<h3 id="1-meta-learning-for-robots">1. Meta-Learning for Robots</h3>

<p>Learn to learn new tasks quickly:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">MAMLPolicy</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Model-Agnostic Meta-Learning for fast adaptation
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">adapt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="s">"""
        Adapt policy to new task using few examples
        support_data: list of (state, action, reward) tuples
        """</span>
        <span class="n">adapted_net</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">adapted_net</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
      
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span> <span class="ow">in</span> <span class="n">support_data</span><span class="p">:</span>
                <span class="n">pred_action</span> <span class="o">=</span> <span class="n">adapted_net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">pred_action</span> <span class="o">-</span> <span class="n">action</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
              
                <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
      
        <span class="c1"># Create new policy with adapted network
</span>        <span class="n">new_policy</span> <span class="o">=</span> <span class="n">MAMLPolicy</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">new_policy</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">adapted_net</span>
        <span class="k">return</span> <span class="n">new_policy</span>

<span class="k">def</span> <span class="nf">meta_train</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">task_distribution</span><span class="p">,</span> <span class="n">meta_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="s">"""
    Meta-train policy across multiple tasks
    """</span>
    <span class="n">meta_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">policy</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
  
    <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">meta_iterations</span><span class="p">):</span>
        <span class="c1"># Sample batch of tasks (placeholder)
</span>        <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_distribution</span><span class="p">.</span><span class="n">sample</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
      
        <span class="n">meta_loss</span> <span class="o">=</span> <span class="mi">0</span>
      
        <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span>
            <span class="c1"># Sample support and query sets (placeholder)
</span>            <span class="n">support_data</span> <span class="o">=</span> <span class="n">task</span><span class="p">.</span><span class="n">sample_data</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">query_data</span> <span class="o">=</span> <span class="n">task</span><span class="p">.</span><span class="n">sample_data</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
          
            <span class="c1"># Adapt to task
</span>            <span class="n">adapted_policy</span> <span class="o">=</span> <span class="n">policy</span><span class="p">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">support_data</span><span class="p">)</span>
          
            <span class="c1"># Evaluate on query set
</span>            <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span> <span class="ow">in</span> <span class="n">query_data</span><span class="p">:</span>
                <span class="n">pred_action</span> <span class="o">=</span> <span class="n">adapted_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">pred_action</span> <span class="o">-</span> <span class="n">action</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
                <span class="n">meta_loss</span> <span class="o">+=</span> <span class="n">loss</span>
      
        <span class="c1"># Meta-update
</span>        <span class="n">meta_optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">meta_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">meta_optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
  
    <span class="k">return</span> <span class="n">policy</span>
</code></pre></div></div>

<h3 id="2-safe-rl-for-robots">2. Safe RL for Robots</h3>

<p>Ensure safe exploration and execution:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SafePolicy</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">safety_constraints</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">constraints</span> <span class="o">=</span> <span class="n">safety_constraints</span>
  
    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Get action from policy
</span>        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
      
        <span class="c1"># Project action to safe set
</span>        <span class="n">safe_action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">project_to_safe</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">safe_action</span>
  
    <span class="k">def</span> <span class="nf">project_to_safe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="s">"""
        Project action to satisfy safety constraints
        """</span>
        <span class="n">safe_action</span> <span class="o">=</span> <span class="n">action</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
      
        <span class="k">for</span> <span class="n">constraint</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">constraints</span><span class="p">:</span>
            <span class="c1"># Check if constraint is violated
</span>            <span class="k">if</span> <span class="ow">not</span> <span class="n">constraint</span><span class="p">.</span><span class="n">is_satisfied</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">safe_action</span><span class="p">):</span>
                <span class="c1"># Project to constraint boundary
</span>                <span class="n">safe_action</span> <span class="o">=</span> <span class="n">constraint</span><span class="p">.</span><span class="n">project</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">safe_action</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">safe_action</span>

<span class="k">class</span> <span class="nc">SafetyConstraint</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">limit</span> <span class="o">=</span> <span class="n">limit</span>
  
    <span class="k">def</span> <span class="nf">is_satisfied</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Check if action violates limit
</span>        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">all</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">limit</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">project</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Project action to satisfy limit
</span>        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">limit</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">limit</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">SafeExploration</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">safety_margin</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">safety_margin</span> <span class="o">=</span> <span class="n">safety_margin</span>
  
    <span class="k">def</span> <span class="nf">explore</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Get action from policy
</span>        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
      
        <span class="c1"># Add exploration noise
</span>        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">noisy_action</span> <span class="o">=</span> <span class="n">action</span> <span class="o">+</span> <span class="n">noise</span>
      
        <span class="c1"># Ensure safety
</span>        <span class="n">safe_action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">ensure_safety</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">noisy_action</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">safe_action</span>
  
    <span class="k">def</span> <span class="nf">ensure_safety</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Check if action is safe
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_safe</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">action</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Return safe action
</span>            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_safe_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">is_safe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Check safety constraints
</span>        <span class="k">return</span> <span class="bp">True</span>  <span class="c1"># Implement safety checks
</span>  
    <span class="k">def</span> <span class="nf">get_safe_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Return safe action (e.g., stop)
</span>        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="3-imitation-learning-for-robots">3. Imitation Learning for Robots</h3>

<p>Learn from human demonstrations:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">BehaviorCloning</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">)</span>
        <span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">demonstrations</span><span class="p">):</span>
        <span class="s">"""
        Train from demonstrations
        demonstrations: list of (state, action) pairs
        """</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
      
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">demonstrations</span><span class="p">:</span>
                <span class="n">pred_action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred_action</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
              
                <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">GAIL</span><span class="p">:</span>
    <span class="s">"""
    Generative Adversarial Imitation Learning
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>
      
        <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">demonstrations</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">n_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="s">"""
        Train using GAIL
        """</span>
        <span class="n">policy_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
      
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
            <span class="c1"># Train discriminator
</span>            <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">demonstrations</span><span class="p">:</span>
                <span class="c1"># Real data
</span>                <span class="n">real_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]))</span>
              
                <span class="c1"># Fake data
</span>                <span class="n">fake_action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">fake_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">fake_action</span><span class="p">]))</span>
              
                <span class="c1"># Discriminator loss
</span>                <span class="n">disc_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">real_prob</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">fake_prob</span><span class="p">)</span>
              
                <span class="n">disc_opt</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">disc_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">disc_opt</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
          
            <span class="c1"># Train policy
</span>            <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
              
                <span class="c1"># Policy loss: maximize discriminator confusion
</span>                <span class="n">prob</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]))</span>
                <span class="n">policy_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">prob</span><span class="p">)</span>
              
                <span class="n">policy_opt</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">policy_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">policy_opt</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
              
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                    <span class="k">break</span>
</code></pre></div></div>

<h2 id="real-world-considerations">Real-World Considerations</h2>

<h3 id="1-hardware-constraints">1. Hardware Constraints</h3>

<p>Real robots have physical limitations:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RobotHardware</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Actuator limits
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">max_velocity</span> <span class="o">=</span> <span class="mf">2.0</span>  <span class="c1"># rad/s
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">max_acceleration</span> <span class="o">=</span> <span class="mf">5.0</span>  <span class="c1"># rad/s^2
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">max_torque</span> <span class="o">=</span> <span class="mf">20.0</span>  <span class="c1"># Nm
</span>      
        <span class="c1"># Sensor constraints
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">sensor_frequency</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Hz
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">sensor_latency</span> <span class="o">=</span> <span class="mf">0.01</span>  <span class="c1"># seconds
</span>      
        <span class="c1"># Power constraints
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">max_power</span> <span class="o">=</span> <span class="mf">100.0</span>  <span class="c1"># Watts
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">battery_life</span> <span class="o">=</span> <span class="mi">3600</span>  <span class="c1"># seconds
</span>      
    <span class="k">def</span> <span class="nf">check_constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="s">"""
        Check if action satisfies hardware constraints
        """</span>
        <span class="c1"># Check velocity limits
</span>        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nb">any</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_velocity</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">False</span>
      
        <span class="c1"># Check torque limits
</span>        <span class="n">torque</span> <span class="o">=</span> <span class="n">action</span> <span class="o">*</span> <span class="mf">10.0</span>  <span class="c1"># Simplified
</span>        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nb">any</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">torque</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_torque</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">False</span>
      
        <span class="k">return</span> <span class="bp">True</span>
  
    <span class="k">def</span> <span class="nf">clip_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="s">"""
        Clip action to satisfy constraints
        """</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">max_velocity</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_velocity</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-communication-delays">2. Communication Delays</h3>

<p>Real robots have communication delays:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DelayedEnvironment</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">action_delay</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">obs_delay</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_delay</span> <span class="o">=</span> <span class="n">action_delay</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">obs_delay</span> <span class="o">=</span> <span class="n">obs_delay</span>
      
        <span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">obs_buffer</span> <span class="o">=</span> <span class="p">[]</span>
  
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">obs_buffer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
      
        <span class="c1"># Fill observation buffer
</span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">obs_delay</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">obs_buffer</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">state</span>
  
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Add action to buffer
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
      
        <span class="c1"># Get delayed action
</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_delay</span><span class="p">:</span>
            <span class="n">delayed_action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_buffer</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">action_delay</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">delayed_action</span> <span class="o">=</span> <span class="n">action</span>
      
        <span class="c1"># Execute delayed action
</span>        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">delayed_action</span><span class="p">)</span>
      
        <span class="c1"># Add observation to buffer
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">obs_buffer</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
      
        <span class="c1"># Get delayed observation
</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">obs_buffer</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">obs_delay</span><span class="p">:</span>
            <span class="n">delayed_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">obs_buffer</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">obs_delay</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">delayed_obs</span> <span class="o">=</span> <span class="n">next_state</span>
      
        <span class="k">return</span> <span class="n">delayed_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span>
</code></pre></div></div>

<h3 id="3-fault-tolerance">3. Fault Tolerance</h3>

<p>Handle hardware failures gracefully:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">FaultTolerantPolicy</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">fallback_policy</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fallback_policy</span> <span class="o">=</span> <span class="n">fallback_policy</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">failure_detected</span> <span class="o">=</span> <span class="bp">False</span>
  
    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Try to get action from main policy
</span>            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
          
            <span class="c1"># Validate action
</span>            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">validate_action</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">action</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Use fallback policy
</span>                <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">fallback_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
      
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># Handle failure
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Policy failure: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">failure_detected</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">fallback_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">validate_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Check if action is valid
</span>        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">action</span><span class="p">).</span><span class="nb">any</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">action</span><span class="p">).</span><span class="nb">any</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">False</span>
        <span class="k">return</span> <span class="bp">True</span>
  
    <span class="k">def</span> <span class="nf">reset_failure</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">failure_detected</span> <span class="o">=</span> <span class="bp">False</span>
</code></pre></div></div>

<h2 id="testing-the-code">Testing the Code</h2>

<p>Hereâ€™s a comprehensive test script to verify all the code examples work correctly:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#!/usr/bin/env python3
</span><span class="s">"""
Test script to verify
"""</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Testing code from RL for Robotics blog post...</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Test 1: DynamicsModel
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 1: DynamicsModel"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">DynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
            <span class="p">)</span>
  
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">state</span> <span class="o">+</span> <span class="n">delta</span>
  
    <span class="n">model</span> <span class="o">=</span> <span class="n">DynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">output</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 10), got </span><span class="si">{</span><span class="n">output</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ DynamicsModel works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— DynamicsModel failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 2: NavigationPolicy
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 2: NavigationPolicy"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">NavigationPolicy</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
  
            <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
            <span class="p">)</span>
  
            <span class="bp">self</span><span class="p">.</span><span class="n">policy_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">()</span>
            <span class="p">)</span>
  
            <span class="bp">self</span><span class="p">.</span><span class="n">value_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
  
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
            <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">value_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">value</span>
  
        <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  
                <span class="n">action</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">action</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>
  
    <span class="n">policy</span> <span class="o">=</span> <span class="n">NavigationPolicy</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">37</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">policy</span><span class="p">.</span><span class="n">get_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">action</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,),</span> <span class="sa">f</span><span class="s">"Expected shape (2,), got </span><span class="si">{</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ NavigationPolicy works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— NavigationPolicy failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 3: WalkingPolicy
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 3: WalkingPolicy"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">WalkingPolicy</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
  
            <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  
            <span class="bp">self</span><span class="p">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">()</span>
            <span class="p">)</span>
  
            <span class="bp">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
  
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">value</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
  
            <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">hidden</span>
  
        <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  
                <span class="n">action</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">new_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">action</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">new_hidden</span>
  
    <span class="n">policy</span> <span class="o">=</span> <span class="n">WalkingPolicy</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">policy</span><span class="p">.</span><span class="n">get_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">action</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">12</span><span class="p">,),</span> <span class="sa">f</span><span class="s">"Expected shape (12,), got </span><span class="si">{</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ WalkingPolicy works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— WalkingPolicy failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 4: MAMLPolicy
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 4: MAMLPolicy"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">copy</span>
  
    <span class="k">class</span> <span class="nc">MAMLPolicy</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">()</span>
            <span class="p">)</span>
  
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
  
        <span class="k">def</span> <span class="nf">adapt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
            <span class="n">adapted_net</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">)</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">adapted_net</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
  
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span> <span class="ow">in</span> <span class="n">support_data</span><span class="p">:</span>
                    <span class="n">pred_action</span> <span class="o">=</span> <span class="n">adapted_net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">pred_action</span> <span class="o">-</span> <span class="n">action</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
  
                    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
  
            <span class="n">new_policy</span> <span class="o">=</span> <span class="n">MAMLPolicy</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">new_policy</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">adapted_net</span>
            <span class="k">return</span> <span class="n">new_policy</span>
  
    <span class="n">policy</span> <span class="o">=</span> <span class="n">MAMLPolicy</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">action</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 3), got </span><span class="si">{</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ MAMLPolicy works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— MAMLPolicy failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 5: BehaviorCloning
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 5: BehaviorCloning"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">BehaviorCloning</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">)</span>
            <span class="p">)</span>
  
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
  
    <span class="n">bc</span> <span class="o">=</span> <span class="n">BehaviorCloning</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">bc</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">action</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 3), got </span><span class="si">{</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ BehaviorCloning works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— BehaviorCloning failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 6: Safety classes
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 6: Safety classes"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">SafetyConstraint</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">limit</span> <span class="o">=</span> <span class="n">limit</span>
  
        <span class="k">def</span> <span class="nf">is_satisfied</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">all</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">limit</span><span class="p">)</span>
  
        <span class="k">def</span> <span class="nf">project</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">limit</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">limit</span><span class="p">)</span>
  
    <span class="n">constraint</span> <span class="o">=</span> <span class="n">SafetyConstraint</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">])</span>
    <span class="n">projected</span> <span class="o">=</span> <span class="n">constraint</span><span class="p">.</span><span class="n">project</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nb">all</span><span class="p">(</span><span class="n">projected</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">),</span> <span class="s">"Projection failed"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ Safety classes work correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— Safety classes failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"All tests passed! âœ“"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">The code in blog post is syntactically correct"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"and should work as expected."</span><span class="p">)</span>
</code></pre></div></div>

<p>To run this test script, save it as <code class="language-plaintext highlighter-rouge">test_robotics_code.py</code> and execute:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python test_robotics_code.py
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>Reinforcement Learning is revolutionizing robotics by enabling robots to learn complex behaviors through experience. While challenges remain, techniques like sim-to-real transfer, safe exploration, and imitation learning are making robot RL increasingly practical.</p>

<h3 id="key-takeaways">Key Takeaways</h3>

<ol>
  <li><strong>Sim-to-Real Transfer:</strong> Train in simulation, transfer to reality</li>
  <li><strong>Safety First:</strong> Always prioritize safety in real-world deployments</li>
  <li><strong>Sample Efficiency:</strong> Use techniques that learn quickly from limited data</li>
  <li><strong>Robustness:</strong> Build policies that handle uncertainty and variations</li>
  <li><strong>Hardware Awareness:</strong> Consider physical constraints in design</li>
</ol>

<h3 id="future-directions">Future Directions</h3>

<ul>
  <li><strong>Better Simulators:</strong> More realistic simulation environments</li>
  <li><strong>Sample Efficient Methods:</strong> Algorithms that learn from fewer examples</li>
  <li><strong>Safe Exploration:</strong> Guaranteed safety during learning</li>
  <li><strong>Multi-Modal Learning:</strong> Combining vision, touch, and proprioception</li>
  <li><strong>Collaborative Robots:</strong> Learning to work with humans</li>
</ul>

<h3 id="resources">Resources</h3>

<ul>
  <li><strong>OpenAI Gym:</strong> Standard interface for RL environments</li>
  <li><strong>MuJoCo:</strong> Physics simulator for robotics</li>
  <li><strong>PyBullet:</strong> Open-source physics engine</li>
  <li><strong>Isaac Gym:</strong> NVIDIAâ€™s GPU-accelerated physics simulator</li>
  <li><strong>Robosuite:</strong> Modular robot learning framework</li>
</ul>

<p>Happy robot learning!</p>


          <!-- Syntax Highlighting -->
          <link href="/assets/css/syntax.css" rel="stylesheet">
          <script src="/assets/scripts/copyCode.js" async></script>

          <!-- Ads -->
          <section aria-label="Advertisements" class="ads mt-4">
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
            <ins class="adsbygoogle"
                 style="display:block"
                 data-ad-client="ca-pub-2976211678184829"
                 data-ad-slot="7658460605"
                 data-ad-format="auto"
                 data-full-width-responsive="true"></ins>
            <script>
              (adsbygoogle = window.adsbygoogle || []).push({});
            </script>
          </section>

        </article>

      </div>

      <!-- Post Navigation -->
      <nav class="post-navigation controls__inner mt-5" aria-label="Post navigation">
        <div class="controls__item prev">
          
            <span>Previous</span>
            <a href="/Spring-Mass-System-Pygame/" rel="prev">
              Spring-Mass System Simulation with Py...
            </a>
          
        </div>

        <div class="controls__item next">
          
            <span>Next</span>
            <a href="/Model-Based-RL/" rel="next">
              Model-Based RL - Learning Environment...
            </a>
          
        </div>
      </nav>

      <!-- Related Posts -->
      
      
      
      
      
      
      
      
      
      
        <section class="related-posts mt-5" aria-label="Related Posts">
          <div class="container">
            <h2 class="related-posts__title">Related Posts</h2>
            <div class="related-posts__grid">
              
                <a class="related-post-card" href="/Q-Learning-from-Scratch/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Part 3: Q-Learning from Scratch - Complete Implementation Guide"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Part 3: Q-Learning from Scratch - Complete Implementation...</h3>
                    <p class="related-post-card__excerpt">
                      
                        Part 3: Q-Learning from Scratch - Complete Implementation Guide Welcome to the third post in...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 03, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/Game-AI-Reinforcement-Learning/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Part 11: Game AI with Reinforcement Learning - Build Intelligent Game Agents"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Part 11: Game AI with Reinforcement Learning - Build Inte...</h3>
                    <p class="related-post-card__excerpt">
                      
                        Part 11: Game AI with Reinforcement Learning - Build Intelligent Game Agents Welcome to the...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 11, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/Markov-Decision-Processes-Explained/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Part 2: Markov Decision Processes Explained - Mathematical Foundation of RL"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Part 2: Markov Decision Processes Explained - Mathematica...</h3>
                    <p class="related-post-card__excerpt">
                      
                        Part 2: Markov Decision Processes Explained - Mathematical Foundation of RL Welcome to the second...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 02, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/Policy-Gradient-Methods/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Part 5: Policy Gradient Methods - Learning Policies Directly"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Part 5: Policy Gradient Methods - Learning Policies Directly</h3>
                    <p class="related-post-card__excerpt">
                      
                        Part 5: Policy Gradient Methods - Learning Policies Directly Welcome to the fifth post in...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 05, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/Earn-Money-with-Python-Modern-Methods/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-earn-money/2026-earn-money_thumb.jpg" 
                           alt="Earn Money with Python - 10 Modern Methods for 2026"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Earn Money with Python - 10 Modern Methods for 2026</h3>
                    <p class="related-post-card__excerpt">
                      
                        # Earn Money with Python - 10 Modern Methods for 2026 Python continues to be...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 20, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/How-to-fix-Address-already-in-use-problem/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/20251213-psutil-port/20251213-psutil-port_thumb.jpg" 
                           alt="Automatically Free a Busy Port in Python Using psutil"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Automatically Free a Busy Port in Python Using psutil</h3>
                    <p class="related-post-card__excerpt">
                      
                        Automatically Free a Busy Port in Python Using psutil If youâ€™ve ever tried to start...
                      
                    </p>
                    <span class="related-post-card__date">
                      Dec 13, 2025
                    </span>
                  </div>
                </a>
              
            </div>
          </div>
        </section>
      

      <!-- Disqus -->
      
        <section class="comments mt-5" aria-label="Comments Section">
          
<section class="comments mt-5" aria-label="Comments Section" style="text-align: center; padding: 50px 0; background-color: #fafafa;">
  <div id="disqus_thread" style="max-width: 800px; margin: 0 auto;"></div>
  <script>

var disqus_config = function () {
this.page.url = 'https://pyshine.com/Reinforcement-Learning-for-Robotics/';
this.page.identifier = 'https://pyshine.com/Reinforcement-Learning-for-Robotics/';
};

(function() {
var d = document, s = d.createElement('script');
s.src = 'https://https-py2ai-github-io.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the comments.</noscript>
</section>


        </section>
      

    </main>

    <footer class="footer">
  <div class="container">
    <nav class="social">
      
      
      
    </nav>
    <span>&copy; 2026 PyShine. All rights reserved.</span>
  </div>
</footer>
<script async src="/assets/js/bundle.js"></script>

<script async>
  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.register('/sw.js').then(function( registration ) {
      console.log('ServiceWorker registration successful with scope: ', registration.scope);
    })
    .catch(function(error) {
      console.log('ServiceWorker registration failed: ', error);
    });
  }
</script>



    <!-- Back to Top Button -->
    <button id="back-to-top" class="back-to-top" aria-label="Back to top">
      <svg viewBox="0 0 24 24" width="24" height="24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <polyline points="18 15 12 9 6 15"></polyline>
      </svg>
    </button>

    <!-- MathJax -->
    


    <!-- Ads -->
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

    <!-- SIDEBAR TOC SCRIPT -->
    <script>
    document.addEventListener("DOMContentLoaded", function() {
      const toc = document.getElementById("toc-list");
      const headings = document.querySelectorAll(
        ".post-content h2:not(.no-toc), .post-content h3:not(.no-toc)"
      );
      if (!toc || headings.length === 0) return;

      const ul = document.createElement("ul");
      headings.forEach(h => {
        const id = h.id || h.textContent.trim().toLowerCase().replace(/\s+/g, "-");
        h.id = id;

        const li = document.createElement("li");
        if (h.tagName === "H3") li.style.marginLeft = "1rem";

        li.innerHTML = `<a href="#${id}">${h.textContent}</a>`;
        ul.appendChild(li);
      });
      toc.appendChild(ul);
    });
    </script>

    <!-- INLINE TOC SCRIPT -->
    <script>
    document.addEventListener("DOMContentLoaded", function() {
      const tocTarget = document.getElementById("inline-toc-list");
      const headings = document.querySelectorAll(
        ".post-content h2:not(.no-toc), .post-content h3:not(.no-toc)"
      );
      if (!tocTarget || headings.length === 0) return;

      const ul = document.createElement("ul");
      headings.forEach(h => {
        const id = h.id || h.textContent.trim().toLowerCase().replace(/\s+/g, "-");
        h.id = id;

        const li = document.createElement("li");
        if (h.tagName === "H3") li.style.marginLeft = "1rem";

        li.innerHTML = `<a href="#${id}">${h.textContent}</a>`;
        ul.appendChild(li);
      });
      tocTarget.appendChild(ul);
    });
    </script>

    <!-- Back to Top Button Script -->
    <script>
    document.addEventListener("DOMContentLoaded", function() {
      const backToTopButton = document.getElementById("back-to-top");
      if (!backToTopButton) return;

      // Show button when scrolled down 300px
      window.addEventListener("scroll", function() {
        if (window.pageYOffset > 300) {
          backToTopButton.classList.add("visible");
        } else {
          backToTopButton.classList.remove("visible");
        }
      });

      // Smooth scroll to top when clicked
      backToTopButton.addEventListener("click", function() {
        window.scrollTo({
          top: 0,
          behavior: "smooth"
        });
      });
    });
    </script>

    <!-- INLINE TOC STYLES -->
    <style>
      .inline-toc-box {
        background: #D4EDFD;
        padding: 15px 20px;
        border-radius: 10px;
        margin-bottom: 25px;
        border: 1px solid #e0e0e0;
      }
      .inline-toc-box ul {
        margin: 0;
        padding-left: 18px;
      }
      .inline-toc-box li {
        margin-bottom: 6px;
      }
      /* Center post navigation */
      .post-navigation.controls__inner {
        justify-content: center !important;
        gap: 4rem;
      }
      /* Related Posts Styles */
      .related-posts {
        margin-top: 3rem;
        padding: 2rem 0;
        border-top: 1px solid #e0e0e0;
      }
      .related-posts .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 0 1rem;
      }
      .related-posts__title {
        font-size: 1.75rem;
        margin-bottom: 1.5rem;
        color: #000000;
        text-align: center;
      }
      .related-posts__grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 1.5rem;
        max-width: 1200px;
        margin: 0 auto;
      }
      .related-post-card {
        display: block;
        text-decoration: none;
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        overflow: hidden;
        transition: box-shadow 0.3s ease, transform 0.3s ease;
      }
      .related-post-card:hover {
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        transform: translateY(-4px);
      }
      .related-post-card__image {
        width: 100%;
        height: 100px;
        background: #f5f5f5;
      }
      .related-post-card__image img {
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      .related-post-card__content {
        padding: 0.75rem;
      }
      .related-post-card__title {
        font-size: 0.95rem;
        margin: 0 0 0.4rem 0;
        color: #000000;
        line-height: 1.3;
        font-weight: 600;
      }
      .related-post-card__excerpt {
        font-size: 0.8rem;
        color: #666;
        margin: 0 0 0.5rem 0;
        line-height: 1.4;
      }
      .related-post-card__date {
        font-size: 0.75rem;
        color: #999;
      }
      @media (max-width: 992px) {
        .related-posts__grid {
          grid-template-columns: repeat(2, 1fr);
        }
      }
      @media (max-width: 600px) {
        .related-posts__grid {
          grid-template-columns: 1fr;
        }
      }
      /* Back to Top Button Styles */
      .back-to-top {
        position: fixed;
        bottom: 30px;
        right: 30px;
        width: 50px;
        height: 50px;
        background: #000000;
        color: #ffffff;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        opacity: 0;
        visibility: hidden;
        transform: translateY(20px);
        transition: all 0.3s ease;
        z-index: 9999;
      }
      .back-to-top.visible {
        opacity: 1;
        visibility: visible;
        transform: translateY(0);
      }
      .back-to-top:hover {
        background: #333333;
        box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
        transform: translateY(-2px);
      }
      .back-to-top:active {
        transform: translateY(0);
      }
      @media (max-width: 768px) {
        .back-to-top {
          bottom: 20px;
          right: 20px;
          width: 45px;
          height: 45px;
        }
      }
    </style>

  </body>
</html>


