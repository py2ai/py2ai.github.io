

  <!DOCTYPE html>
<html lang="en" itemscope itemtype="https://schema.org/Article">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Canonical URL - redirect www to non-www -->
  <link rel="canonical" href="https://pyshine.com/Model-Based-RL/">

  <!-- Pinterest & Google verification -->
  <meta name="p:domain_verify" content="fb68a8459fe32b8b072bcd5cc620d125"/>
  <meta name="google-site-verification" content="WAkFPi5cvufClnQetgIl0STmvvwHhVf8jfyENFWhsxU" />
  <meta name="google-site-verification" content="g2pFZlv-92XQD67BPgiVHsvZ4TZH13Ucvmmvvv36kU4" />

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Model-Based RL - Learning Environment Models for Planning | PyShine</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Model-Based RL - Learning Environment Models for Planning" />
<meta name="author" content="PyShine Team" />
<meta property="og:locale" content="en" />
<meta name="description" content="Learn Model-Based Reinforcement Learning. Understand how to learn environment models for planning, explore popular algorithms, and implement toy examples with code." />
<meta property="og:description" content="Learn Model-Based Reinforcement Learning. Understand how to learn environment models for planning, explore popular algorithms, and implement toy examples with code." />
<link rel="canonical" href="https://pyshine.com/Model-Based-RL/" />
<meta property="og:url" content="https://pyshine.com/Model-Based-RL/" />
<meta property="og:site_name" content="PyShine" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-02-19T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Model-Based RL - Learning Environment Models for Planning" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"PyShine Team"},"dateModified":"2026-02-19T00:00:00+00:00","datePublished":"2026-02-19T00:00:00+00:00","description":"Learn Model-Based Reinforcement Learning. Understand how to learn environment models for planning, explore popular algorithms, and implement toy examples with code.","headline":"Model-Based RL - Learning Environment Models for Planning","mainEntityOfPage":{"@type":"WebPage","@id":"https://pyshine.com/Model-Based-RL/"},"name":"{{ page.title escape }}","url":"https://pyshine.com/Model-Based-RL/"}</script>
<!-- End Jekyll SEO tag -->
  <!-- This will generate the canonical link automatically -->

  <script src="https://analytics.ahrefs.com/analytics.js" data-key="Im0K82YsmEDy08+6wyUIZA" async></script>

  <!-- Favicon & App Icons -->
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/img/icons/apple-touch-icon.png?v=qA3OXqyw77">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/icons/favicon-32x32.png?v=qA3OXqyw77">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/img/icons/favicon-16x16.png?v=qA3OXqyw77">
  <link rel="manifest" href="/assets/img/icons/manifest.json?v=qA3OXqyw77">
  <link rel="mask-icon" href="/assets/img/icons/safari-pinned-tab.svg?v=qA3OXqyw77" color="#5bbad5">
  <link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77">
  <!--[if IE]><link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77"><![endif]-->

  <!-- App & Theme Info -->
  <meta name="apple-mobile-web-app-title" content="Sleek">
  <meta name="application-name" content="Sleek">
  <meta name="msapplication-config" content="/assets/img/icons/browserconfig.xml?v=qA3OXqyw77">
  <meta name="theme-color" content="#ffffff">

  
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-TCVFBKF"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'GTM-TCVFBKF');
</script>

  

  <!-- Critical CSS Inline -->
  <style class="inlineCSS">
    h1{color:#313237;margin-top:0;margin-bottom:.5rem}.dark-bg{background-color:#19d319}@media (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:last-of-type,.post-card:nth-child(2n+2){margin-right:0}}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figure,main{display:block}figure{margin:1em 40px}a{background-color:transparent;-webkit-text-decoration-skip:objects}img{border-style:none}svg:not(:root){overflow:hidden}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}body{-webkit-overflow-scrolling:touch}*,::after,::before{-webkit-box-sizing:inherit;box-sizing:inherit}.site{display:-webkit-box;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.site__content{-webkit-box-flex:1;-ms-flex:1;flex:1}img{max-width:100%;height:auto;width:auto;vertical-align:middle}figure{margin:0}body{background-color:#fff;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Hiragino Sans GB","Microsoft YaHei","WenQuanYi Micro Hei",sans-serif;font-size:1rem;line-height:1.5;color:#343851;-webkit-font-smoothing:antialiased;-webkit-text-size-adjust:100%}p{margin-top:0;margin-bottom:1.25rem}h1,h2{color:#313237;margin-top:0;margin-bottom:.5rem}a{color:#277cea;text-decoration:none;border-bottom:1px dashed #277cea}.blur{background:#fff;filter:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg"><filter id="filter"><feGaussianBlur stdDeviation="16" /></filter></svg>#filter');-webkit-filter:blur(1rem);filter:blur(1rem)}.container{padding:0 20px}@media (min-width:0){.container{max-width:auto;margin:0 auto}}@media (min-width:36em){.container{max-width:540px;margin:0 auto}}@media (min-width:48em){.container{max-width:720px;margin:0 auto}}@media (min-width:62em){.container{max-width:960px;margin:0 auto}}@media (min-width:75em){.container{max-width:1170px;margin:0 auto}}.header{background-color:#fff;color:#343851;position:absolute;z-index:4;width:100%;top:0;left:0;will-change:transform;-webkit-transform:translateY(0);transform:translateY(0)}.header a{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-bottom:0}.header__logo{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;overflow:hidden;padding:19px 0;margin-right:1.25rem;outline:0;border-bottom:0;color:#313237}.header__logo .header__logo--container{width:58px}.header__logo .header__logo--container .logo{fill:currentColor}.header__inner{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:3.75em;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.header__links{padding-bottom:.5rem;display:none;position:absolute;top:3.75em;left:0;width:100%;height:auto;background:#fff}.header__link{color:#343851;padding:.938rem 0;border-top:1px solid #ededed}.header__toggle{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;width:44px;height:100%;background-color:transparent;padding-left:1.25rem}.header__toggle span{display:block;position:relative;margin-top:4px;background-color:#343851;width:100%;height:2px;border-radius:1px}.header__toggle span:first-child{margin-top:0}@media (min-width:62em){.header__toggle{display:none;visibility:hidden}.header__links{position:static;padding:0;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;visibility:visible;width:auto;height:100%}.header__links-wrapper{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;padding:0}.header__link{position:relative;padding:.938rem 1rem;border:0;height:100%}.header__link::after{content:"";display:block;position:absolute;left:0;bottom:0;height:3px;width:100%;-webkit-transform:scaleX(0);transform:scaleX(0);background:#277cea}}.post-card{display:block;position:relative;width:100%;min-height:250px;border-radius:4px;overflow:hidden;background-color:#fff;-webkit-box-shadow:0 1px 3px rgba(0,0,0,.08);box-shadow:0 1px 3px rgba(0,0,0,.08);margin-bottom:2.25rem;border-bottom:0}@media (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:0}}@media (min-width:75em){.post-card{width:31.25%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:3.125%}}.post-card__label{position:absolute;top:1.5rem;left:1.5rem;z-index:2}.post-card__thumb{margin:0;background:#fff;position:relative;overflow:hidden}.post-card__thumb::after{content:"";display:block;height:0;width:100%;padding-bottom:56.25%}.post-card__thumb>*{position:absolute;top:0;left:0;width:100%;height:100%;display:block}.post-card__inner{padding:1.875rem 1.25rem .625rem;color:#838c8d}.post-card__header{margin-bottom:.75rem}.post-card__header .post-card__meta{font-size:.875rem}.label{padding:0 10px;margin-bottom:1rem;display:inline-block;line-height:20px;font-size:.75rem;text-transform:uppercase;letter-spacing:1px;color:rgba(255,255,255,.8);border:2px solid rgba(255,255,255,.5);border-radius:100px}.hero{margin:3.75rem auto 0;min-height:16.25rem;width:100%;position:relative;background-color:#dde5ea;background-repeat:no-repeat;background-position:50%;background-size:cover}@media (min-width:62em){.hero{margin:0 auto;height:36em}}.hero::before{position:absolute;display:block;content:"";top:0;left:0;width:100%;height:100%;background:rgba(52,56,81,.8)}.hero__wrap{position:absolute;margin:auto;top:50%;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);text-align:center;color:rgba(255,255,255,.8);width:100%;max-width:90%;z-index:1}.hero__wrap .hero__title{font-size:1.8em;color:#fff}.blog{background-color:#f9f9f9}.post-list{padding-top:2.5em;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-flex:1;-ms-flex:1 0 auto;flex:1 0 auto}@media (min-width:48em){.hero__wrap{max-width:40em}.hero__wrap .hero__title{padding:1rem 0;font-size:2.625em;line-height:3.125rem}.post-list{padding-top:5em}}
  </style>

  <!-- Main CSS -->
  <link rel="preload" href="/assets/css/main.css" as="style" onload="this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="/assets/css/main.css"></noscript>

  <script type="text/javascript">
    /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
(function(w){"use strict";if(!w.loadCSS){w.loadCSS=function(){}}
var rp=loadCSS.relpreload={};rp.support=(function(){var ret;try{ret=w.document.createElement("link").relList.supports("preload")}catch(e){ret=!1}
return function(){return ret}})();rp.bindMediaToggle=function(link){var finalMedia=link.media||"all";function enableStylesheet(){link.media=finalMedia}
if(link.addEventListener){link.addEventListener("load",enableStylesheet)}else if(link.attachEvent){link.attachEvent("onload",enableStylesheet)}
setTimeout(function(){link.rel="stylesheet";link.media="only x"});setTimeout(enableStylesheet,3000)};rp.poly=function(){if(rp.support()){return}
var links=w.document.getElementsByTagName("link");for(var i=0;i<links.length;i++){var link=links[i];if(link.rel==="preload"&&link.getAttribute("as")==="style"&&!link.getAttribute("data-loadcss")){link.setAttribute("data-loadcss",!0);rp.bindMediaToggle(link)}}};if(!rp.support()){rp.poly();var run=w.setInterval(rp.poly,500);if(w.addEventListener){w.addEventListener("load",function(){rp.poly();w.clearInterval(run)})}else if(w.attachEvent){w.attachEvent("onload",function(){rp.poly();w.clearInterval(run)})}}
if(typeof exports!=="undefined"){exports.loadCSS=loadCSS}
else{w.loadCSS=loadCSS}}(typeof global!=="undefined"?global:this))

  </script>

  <!-- MathJax -->
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>


  <body class="site" itemscope itemtype="https://schema.org/WebPage">

    
      <!-- Google Tag Manager (noscript) -->
      <noscript>
        <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TCVFBKF"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
      </noscript>
      <!-- End Google Tag Manager -->
    

    <header class="header"
  itemscope
  itemtype="http://schema.org/SiteNavigationElement"
  aria-label="Main navigation">

  <div class="container">
    <div class="header__inner">

      <!-- Logo -->
      <a class="header__logo" href="/">
        <div class="header__logo--container">
          <?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 16.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24" xml:space="preserve">
<g>
	<path d="M18.121,9.88l-7.832-7.836c-0.155-0.158-0.428-0.155-0.584,0L1.842,9.913c-0.262,0.263-0.073,0.705,0.292,0.705h2.069v7.042c0,0.227,0.187,0.414,0.414,0.414h3.725c0.228,0,0.414-0.188,0.414-0.414v-3.313h2.483v3.313c0,0.227,0.187,0.414,0.413,0.414h3.726c0.229,0,0.414-0.188,0.414-0.414v-7.042h2.068h0.004C18.331,10.617,18.389,10.146,18.121,9.88 M14.963,17.245h-2.896v-3.313c0-0.229-0.186-0.415-0.414-0.415H8.342c-0.228,0-0.414,0.187-0.414,0.415v3.313H5.032v-6.628h9.931V17.245z M3.133,9.79l6.864-6.868l6.867,6.868H3.133z"></path>

	
	
</g>
</svg>

        </div>
      </a>

      <!-- Navigation -->
      <nav class="header__links">
        <div class="header__links-wrapper">

          
            
              <a class="header__link" href="/">
                Home
              </a>
            
          
            
              <a class="header__link" href="/categories">
                Posts
              </a>
            
          
            

            <!-- Applications Dropdown -->
            <div class="header__dropdown">
              <span class="header__link header__dropdown-toggle">
                Applications
                <span class="dropdown-arrow">â–¾</span>
              </span>

              <div class="header__dropdown-menu">
                
                  <a class="header__dropdown-item"
                     href="/photo_correction">
                    Online Photo Correction
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/photo">
                    Online Passport Photo 20KB
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/finger.html">
                    Online Fingers Scanner
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/avatars">
                    Online Make Avatars
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/kanban/debounce.html">
                    Online Reminder App
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/converter.html">
                    Online Image Resize
                  </a>
                
              </div>
            </div>

            
          
            

            <!-- Applications Dropdown -->
            <div class="header__dropdown">
              <span class="header__link header__dropdown-toggle">
                Games
                <span class="dropdown-arrow">â–¾</span>
              </span>

              <div class="header__dropdown-menu">
                
                  <a class="header__dropdown-item"
                     href="/games/snake">
                    Snake Game
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/flappy-bird">
                    Flappy Bird
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/tetris">
                    Tetris
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/memory-match">
                    Memory Match
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/pong">
                    Pong
                  </a>
                
                  <a class="header__dropdown-item"
                     href="/games/2048">
                    2048
                  </a>
                
              </div>
            </div>

            
          
            
              <a class="header__link" href="/about">
                About
              </a>
            
          
            
              <a class="header__link" href="/contact">
                Contact
              </a>
            
          
            
              <a class="header__link" href="/privacy">
                Privacy Policy
              </a>
            
          
            
              <a class="header__link" href="/disclaimer">
                Disclaimer
              </a>
            
          

        </div>
      </nav>

      <!-- Language Switcher -->
      

      <!-- Mobile Toggle -->
      <div class="header__toggle">
        <span></span><span></span><span></span>
      </div>

    </div>
  </div>

<style>
/* ==================================================
   ðŸ”’ HEADER â€” ALWAYS VISIBLE, FULL WIDTH COLOR
================================================== */
.header{
  position: fixed;
  top: 0;
  left: 0;
  width: 100vw;           /* full width */
  z-index: 10000;
  background: #FFFFFF;    /* uniform header background */
  box-shadow: 0 2px 12px rgba(0,0,0,.35);
  transform: none !important;
  transition: none !important;
}

/* Lock height to avoid reflow */
.header__inner{
  min-height: 72px;
  display: flex;
  align-items: center;
  justify-content: space-between;
}

/* Prevent content hiding under fixed header */
body{
  padding-top: 72px;
}

/* ===============================
   NAV BASE
=============================== */
.header__links-wrapper{
  display:flex;
  align-items:center;
  gap:1.5rem;
}

.header__link,
.header__dropdown-toggle{
  display:inline-flex;
  align-items:center;
  gap:6px;
  cursor:pointer;
  font-size:16px;
  font-weight:500;
  color:#000000;
}

/* ===============================
   DROPDOWN
=============================== */
.header__dropdown{
  position:relative;
}

.dropdown-arrow{
  font-size:1.4em;
  transition:transform .2s ease;
}

.header__dropdown:hover .dropdown-arrow{
  transform:rotate(180deg);
}

.header__dropdown-menu{
  position:absolute;
  top:100%;
  left:0;
  min-width:220px;
  background:#121212;
  border:1px solid #333;
  border-radius:10px;
  padding:6px 0;
  display:none;
  z-index:9999;
}

.header__dropdown:hover .header__dropdown-menu{
  display:block;
}

.header__dropdown-item{
  display:block;
  padding:10px 16px;
  color:#eaeaea;
  text-decoration:none;
}

.header__dropdown-item:hover{
  background:#1f1f1f;
}

/* ===============================
   MOBILE
=============================== */
@media (max-width:768px){

  body{
    padding-top: 64px;
  }

  .header__inner{
    min-height: 64px;
  }

  .header__links-wrapper{
    flex-direction:column;
    align-items:stretch;
    gap:0;
  }

  .header__dropdown-toggle{
    justify-content:space-between;
    padding:14px 16px;
  }

  .header__dropdown-menu{
    position:static;
    display:none;
    background:#0f0f0f;
    border:none;
  }

  .header__dropdown:hover .header__dropdown-menu{
    display:block;
  }

  .header__dropdown-item{
    padding:14px 20px;
    background:#1a1a1a;
    border-top:1px solid #2a2a2a;
    font-size:15px;
  }
}

/* ===============================
   LANGUAGE SWITCHER
=============================== */
.header__lang-switcher{
  display:inline-flex;
  gap:.5rem;
  align-items:center;
  font-size:1.3rem;
  margin-left:1rem;
}
.lang-flag.active{ text-decoration:underline }
.lang-flag.disabled{ opacity:.5; filter:grayscale(100%) }

</style>
</header>


    
      <div class="hero lazyload"
           data-bg="https://pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl.jpg"
           role="img"
           aria-label="Model-Based RL - Learning Environment Models for Planning">
    
        <div class="hero__wrap">

          
            <div class="hero__categories">
              
                <a class="label"
                   href="/categories/#Machine Learning"
                   aria-label="Category: Machine Learning">
                   Machine Learning
                </a>
                &nbsp;
              
                <a class="label"
                   href="/categories/#AI"
                   aria-label="Category: AI">
                   AI
                </a>
                &nbsp;
              
                <a class="label"
                   href="/categories/#Python"
                   aria-label="Category: Python">
                   Python
                </a>
                &nbsp;
              
                <a class="label"
                   href="/categories/#Deep RL"
                   aria-label="Category: Deep RL">
                   Deep RL
                </a>
                
              
            </div>
          

          <h1 class="hero__title" itemprop="headline">Model-Based RL - Learning Environment Models for Planning</h1>

          <p class="hero__meta">
            <time datetime="2026-02-19T00:00:00+00:00" itemprop="datePublished">
              19 Feb 2026
            </time>
            &nbsp;Â·&nbsp;
            
            <span itemprop="timeRequired">
              
                65 mins read
              
            </span>
          </p>
        </div>
      </div>

    <main class="site__content" role="main">
      <div class="container post-layout">

        <!-- SIDEBAR TOC -->
        <aside class="post-toc" id="post-toc">
          <h3 class="no-toc">Contents</h3>
          <nav id="toc-list"></nav>
        </aside>

        <!-- MAIN CONTENT -->
        <article class="post-content"
                 itemprop="articleBody"
                 itemscope itemtype="https://schema.org/Article">

          <!-- INLINE TOC -->
          <div id="inline-toc" class="inline-toc-box">
            <h3 class="no-toc">Contents</h3>
            <nav id="inline-toc-list"></nav>
          </div>

          <h1 id="model-based-rl---learning-environment-models-for-planning">Model-Based RL - Learning Environment Models for Planning</h1>

<p>Welcome to our comprehensive guide on <strong>Model-Based Reinforcement Learning</strong>! In this post, weâ€™ll explore how Model-Based RL learns environment dynamics to enable planning and more sample-efficient learning. Weâ€™ll cover the fundamental concepts, popular algorithms, and implement working toy examples.</p>

<h2 id="introduction-what-is-model-based-rl">Introduction: What is Model-Based RL?</h2>

<p>Model-Based Reinforcement Learning is an approach where the agent learns a model of the environmentâ€™s dynamics and uses this model for planning and decision-making. Unlike model-free methods that learn directly from experience, model-based methods learn how the environment works.</p>

<h3 id="model-free-vs-model-based-rl">Model-Free vs Model-Based RL</h3>

<p><strong>Model-Free RL (DQN, PPO, SAC):</strong></p>

<ul>
  <li>Learns policy or value functions directly</li>
  <li>No explicit model of environment</li>
  <li>Requires many samples</li>
  <li>Harder to plan ahead</li>
  <li>Examples: DQN, PPO, SAC, A3C</li>
</ul>

<p><strong>Model-Based RL:</strong></p>

<ul>
  <li>Learns environment dynamics model</li>
  <li>Uses model for planning</li>
  <li>More sample efficient</li>
  <li>Can plan multiple steps ahead</li>
  <li>Examples: PETS, MBPO, Dreamer, AlphaZero</li>
</ul>

<h3 id="why-model-based-rl">Why Model-Based RL?</h3>

<p><strong>Sample Efficiency:</strong></p>

<ul>
  <li>Learn from fewer interactions</li>
  <li>Simulate experience using learned model</li>
  <li>Reuse model for multiple tasks</li>
  <li>Faster learning in data-scarce scenarios</li>
</ul>

<p><strong>Planning:</strong></p>

<ul>
  <li>Look ahead multiple steps</li>
  <li>Optimize actions using model</li>
  <li>Handle long-term dependencies</li>
  <li>Better strategic decision-making</li>
</ul>

<p><strong>Generalization:</strong></p>

<ul>
  <li>Transfer learned models to new tasks</li>
  <li>Adapt to changing environments</li>
  <li>Combine with model-free methods</li>
  <li>Robust to distribution shift</li>
</ul>

<h2 id="the-model-based-rl-framework">The Model-Based RL Framework</h2>

<h3 id="core-components">Core Components</h3>

<h4 id="1-dynamics-model">1. <strong>Dynamics Model</strong></h4>

<p>Learns to predict next state given current state and action:</p>

\[s_{t+1} = f(s_t, a_t) + \epsilon\]

<p>Where:</p>

<ul>
  <li>$s_t$: Current state</li>
  <li>$a_t$: Current action</li>
  <li>$f$: Learned dynamics model</li>
  <li>$\epsilon$: Prediction noise</li>
</ul>

<h4 id="2-planning-algorithm">2. <strong>Planning Algorithm</strong></h4>

<p>Uses learned model to find optimal actions:</p>

<ul>
  <li><strong>Random Shooting:</strong> Sample random action sequences, pick best</li>
  <li><strong>Cross-Entropy Method (CEM):</strong> Iteratively refine action sequences</li>
  <li><strong>Model Predictive Control (MPC):</strong> Optimize actions over horizon</li>
  <li><strong>Tree Search:</strong> Explore action space systematically</li>
</ul>

<h4 id="3-data-collection">3. <strong>Data Collection</strong></h4>

<p>Gathers experience from real environment:</p>

<ul>
  <li>Exploration strategies</li>
  <li>Balance exploration and exploitation</li>
  <li>Update model with new data</li>
  <li>Maintain diverse dataset</li>
</ul>

<h2 id="toy-example-simple-grid-world">Toy Example: Simple Grid World</h2>

<p>Letâ€™s start with a simple 2D grid world to illustrate model-based concepts:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>

<span class="k">class</span> <span class="nc">GridWorld</span><span class="p">:</span>
    <span class="s">"""
    Simple 2D grid world environment
    Agent moves in 4 directions, collects rewards
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">goal_pos</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">goal_pos</span> <span class="o">=</span> <span class="n">goal_pos</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      
        <span class="c1"># Action space: 0=up, 1=down, 2=left, 3=right
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">state_space</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
      
        <span class="c1"># Obstacles
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">obstacles</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span>
      
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">()</span>
  
    <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Get current position
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span>
      
        <span class="c1"># Apply action
</span>        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># up
</span>            <span class="n">new_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># down
</span>            <span class="n">new_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># left
</span>            <span class="n">new_pos</span> <span class="o">=</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># right
</span>            <span class="n">new_pos</span> <span class="o">=</span> <span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
      
        <span class="c1"># Check obstacles
</span>        <span class="k">if</span> <span class="n">new_pos</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">obstacles</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">=</span> <span class="n">new_pos</span>
      
        <span class="c1"># Compute reward
</span>        <span class="n">reward</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>  <span class="c1"># Step penalty
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">==</span> <span class="bp">self</span><span class="p">.</span><span class="n">goal_pos</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Goal reward
</span>      
        <span class="c1"># Check done
</span>        <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">==</span> <span class="bp">self</span><span class="p">.</span><span class="n">goal_pos</span>
      
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">(),</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="p">{}</span>
  
    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="p">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">size</span><span class="p">))</span>
      
        <span class="c1"># Mark goal
</span>        <span class="n">grid</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">goal_pos</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">goal_pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.5</span>
      
        <span class="c1"># Mark obstacles
</span>        <span class="k">for</span> <span class="n">obs</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">obstacles</span><span class="p">:</span>
            <span class="n">grid</span><span class="p">[</span><span class="n">obs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">obs</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
      
        <span class="c1"># Mark agent
</span>        <span class="n">grid</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
      
        <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'RdYlGn'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s">"Agent at </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span><span class="si">}</span><span class="s">, Goal at </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">goal_pos</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="learning-the-dynamics-model">Learning the Dynamics Model</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>

<span class="k">class</span> <span class="nc">GridWorldDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Neural network to predict next state in grid world
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
      
        <span class="c1"># Encode state and action
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
      
        <span class="c1"># Predict next state
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
      
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># One-hot encode action
</span>        <span class="n">action_onehot</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">action_onehot</span><span class="p">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action</span><span class="p">.</span><span class="nb">long</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span>
      
        <span class="c1"># Concatenate state and action
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action_onehot</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      
        <span class="c1"># Encode and decode
</span>        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">next_state</span>
  
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="s">"""
        Predict next state (handles numpy inputs)
        """</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">integer</span><span class="p">)):</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">action</span><span class="p">]])</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
          
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
          
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">pred</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">collect_data</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">n_episodes</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="s">"""
    Collect experience data from environment
    """</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
  
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_episodes</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
      
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
            <span class="c1"># Random action
</span>            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
          
            <span class="c1"># Step environment
</span>            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
          
            <span class="c1"># Store transition
</span>            <span class="n">data</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">'state'</span><span class="p">:</span> <span class="n">state</span><span class="p">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="s">'action'</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                <span class="s">'next_state'</span><span class="p">:</span> <span class="n">next_state</span><span class="p">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="s">'reward'</span><span class="p">:</span> <span class="n">reward</span>
            <span class="p">})</span>
          
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                <span class="k">break</span>
  
    <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">train_dynamics_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
    <span class="s">"""
    Train dynamics model on collected data
    """</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
  
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Shuffle data
</span>        <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
      
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
          
            <span class="c1"># Prepare batch
</span>            <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'state'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
            <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'action'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
            <span class="n">next_states</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'next_state'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
          
            <span class="c1"># Forward pass
</span>            <span class="n">pred_next_states</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">)</span>
          
            <span class="c1"># Compute loss
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred_next_states</span><span class="p">,</span> <span class="n">next_states</span><span class="p">)</span>
          
            <span class="c1"># Backward pass
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
          
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
      
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s">, Loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># Train dynamics model
</span><span class="n">env</span> <span class="o">=</span> <span class="n">GridWorld</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">collect_data</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">n_episodes</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GridWorldDynamicsModel</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">train_dynamics_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Test model
</span><span class="n">test_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">test_action</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># right
</span><span class="n">predicted_next</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_state</span><span class="p">,</span> <span class="n">test_action</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"State: </span><span class="si">{</span><span class="n">test_state</span><span class="si">}</span><span class="s">, Action: </span><span class="si">{</span><span class="n">test_action</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Predicted next state: </span><span class="si">{</span><span class="n">predicted_next</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="planning-with-learned-model">Planning with Learned Model</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RandomShootingPlanner</span><span class="p">:</span>
    <span class="s">"""
    Plan actions by sampling random action sequences
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">horizon</span> <span class="o">=</span> <span class="n">horizon</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">n_samples</span>
  
    <span class="k">def</span> <span class="nf">plan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="s">"""
        Find best action sequence using random shooting
        """</span>
        <span class="n">best_action</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">best_reward</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">'-inf'</span><span class="p">)</span>
      
        <span class="c1"># Sample random action sequences
</span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span><span class="p">):</span>
            <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">horizon</span><span class="p">)</span>
          
            <span class="c1"># Simulate trajectory
</span>            <span class="n">current_state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
          
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
                <span class="c1"># Predict next state
</span>                <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
              
                <span class="c1"># Compute reward (distance to goal)
</span>                <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">next_state</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
                <span class="n">reward</span> <span class="o">=</span> <span class="o">-</span><span class="n">distance</span>
                <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
              
                <span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span>
          
            <span class="c1"># Update best
</span>            <span class="k">if</span> <span class="n">total_reward</span> <span class="o">&gt;</span> <span class="n">best_reward</span><span class="p">:</span>
                <span class="n">best_reward</span> <span class="o">=</span> <span class="n">total_reward</span>
                <span class="n">best_action</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      
        <span class="k">return</span> <span class="n">best_action</span>

<span class="k">class</span> <span class="nc">CrossEntropyMethodPlanner</span><span class="p">:</span>
    <span class="s">"""
    Plan actions using Cross-Entropy Method (CEM)
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_elite</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">horizon</span> <span class="o">=</span> <span class="n">horizon</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">n_samples</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_elite</span> <span class="o">=</span> <span class="n">n_elite</span>
  
    <span class="k">def</span> <span class="nf">plan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">n_iterations</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="s">"""
        Find best action sequence using CEM
        """</span>
        <span class="c1"># Initialize action distribution
</span>        <span class="n">action_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">horizon</span><span class="p">)</span>
        <span class="n">action_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">horizon</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span>
      
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
            <span class="c1"># Sample action sequences
</span>            <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
          
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span><span class="p">):</span>
                <span class="c1"># Sample action sequence
</span>                <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">action_mean</span><span class="p">,</span> <span class="n">action_std</span><span class="p">)</span>
                <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span> <span class="o">-</span> <span class="mi">1</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
              
                <span class="c1"># Simulate trajectory
</span>                <span class="n">current_state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
              
                <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
                    <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
                    <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">next_state</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
                    <span class="n">reward</span> <span class="o">=</span> <span class="o">-</span><span class="n">distance</span>
                    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                    <span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span>
              
                <span class="n">samples</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
                <span class="n">rewards</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_reward</span><span class="p">)</span>
          
            <span class="c1"># Select elite samples
</span>            <span class="n">elite_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">rewards</span><span class="p">)[</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">n_elite</span><span class="p">:]</span>
            <span class="n">elite_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">elite_indices</span><span class="p">]</span>
          
            <span class="c1"># Update distribution
</span>            <span class="n">action_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">elite_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">action_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">elite_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span>
      
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">action_mean</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Test planners
</span><span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>

<span class="c1"># Random shooting planner
</span><span class="n">rs_planner</span> <span class="o">=</span> <span class="n">RandomShootingPlanner</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">rs_planner</span><span class="p">.</span><span class="n">plan</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Random Shooting Planner action: </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># CEM planner
</span><span class="n">cem_planner</span> <span class="o">=</span> <span class="n">CrossEntropyMethodPlanner</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">cem_planner</span><span class="p">.</span><span class="n">plan</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"CEM Planner action: </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="toy-example-continuous-control-cartpole">Toy Example: Continuous Control (CartPole)</h2>

<p>Letâ€™s implement model-based RL on a continuous control task:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">CartPoleDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Learn dynamics model for CartPole environment
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
      
        <span class="c1"># Encoder
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
      
        <span class="c1"># Predict state delta
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">delta_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
      
        <span class="c1"># Predict reward
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">reward_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      
        <span class="c1"># Predict done
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">done_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Concatenate state and action
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      
        <span class="c1"># Encode
</span>        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      
        <span class="c1"># Predictions
</span>        <span class="n">delta</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">delta_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">reward_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">done</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">done_head</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>
      
        <span class="k">return</span> <span class="n">delta</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span>
  
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="s">"""
        Predict next state, reward, done
        """</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
          
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
          
            <span class="n">delta</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="n">state</span> <span class="o">+</span> <span class="n">delta</span>
          
            <span class="k">return</span> <span class="p">(</span><span class="n">next_state</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">(),</span> 
                    <span class="n">reward</span><span class="p">.</span><span class="n">item</span><span class="p">(),</span> 
                    <span class="n">done</span><span class="p">.</span><span class="n">item</span><span class="p">())</span>

<span class="k">class</span> <span class="nc">EnsembleDynamicsModel</span><span class="p">:</span>
    <span class="s">"""
    Ensemble of dynamics models for uncertainty estimation
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_models</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">state_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">CartPoleDynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">)</span>
        <span class="p">]</span>
  
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="s">"""
        Predict with ensemble, return mean and std
        """</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
      
        <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="n">predictions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
      
        <span class="c1"># Compute mean and std
</span>        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
        <span class="n">mean_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">std_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">mean_pred</span><span class="p">,</span> <span class="n">std_pred</span>

<span class="k">def</span> <span class="nf">collect_cartpole_data</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">n_episodes</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="s">"""
    Collect data from CartPole environment
    """</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
  
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_episodes</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
      
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
            <span class="c1"># Random action
</span>            <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">sample</span><span class="p">()</span>
          
            <span class="c1"># Step environment
</span>            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
          
            <span class="c1"># Store transition
</span>            <span class="n">data</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">'state'</span><span class="p">:</span> <span class="n">state</span><span class="p">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="s">'action'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">action</span><span class="p">]),</span>
                <span class="s">'next_state'</span><span class="p">:</span> <span class="n">next_state</span><span class="p">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="s">'reward'</span><span class="p">:</span> <span class="n">reward</span><span class="p">,</span>
                <span class="s">'done'</span><span class="p">:</span> <span class="n">done</span>
            <span class="p">})</span>
          
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                <span class="k">break</span>
  
    <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">train_cartpole_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="s">"""
    Train CartPole dynamics model
    """</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="n">mse_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">bce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BCELoss</span><span class="p">()</span>
  
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
      
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
          
            <span class="c1"># Prepare batch
</span>            <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'state'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
            <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'action'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
            <span class="n">next_states</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'next_state'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
            <span class="n">rewards</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'reward'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">dones</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'done'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
          
            <span class="c1"># Forward pass
</span>            <span class="n">pred_delta</span><span class="p">,</span> <span class="n">pred_reward</span><span class="p">,</span> <span class="n">pred_done</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">)</span>
          
            <span class="c1"># Compute losses
</span>            <span class="n">delta_loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">pred_delta</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">-</span> <span class="n">states</span><span class="p">)</span>
            <span class="n">reward_loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">pred_reward</span><span class="p">,</span> <span class="n">rewards</span><span class="p">)</span>
            <span class="n">done_loss</span> <span class="o">=</span> <span class="n">bce_loss</span><span class="p">(</span><span class="n">pred_done</span><span class="p">,</span> <span class="n">dones</span><span class="p">)</span>
          
            <span class="n">loss</span> <span class="o">=</span> <span class="n">delta_loss</span> <span class="o">+</span> <span class="n">reward_loss</span> <span class="o">+</span> <span class="n">done_loss</span>
          
            <span class="c1"># Backward pass
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
          
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
      
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s">, Loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># Train CartPole model
</span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">'CartPole-v1'</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">collect_cartpole_data</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">n_episodes</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">CartPoleDynamicsModel</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">train_cartpole_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># Test model
</span><span class="n">test_state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">test_action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
<span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_state</span><span class="p">,</span> <span class="n">test_action</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"State: </span><span class="si">{</span><span class="n">test_state</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Action: </span><span class="si">{</span><span class="n">test_action</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Predicted next state: </span><span class="si">{</span><span class="n">next_state</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Predicted reward: </span><span class="si">{</span><span class="n">reward</span><span class="si">}</span><span class="s">, done: </span><span class="si">{</span><span class="n">done</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="mpc-with-learned-model">MPC with Learned Model</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MPCPlanner</span><span class="p">:</span>
    <span class="s">"""
    Model Predictive Control planner
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">horizon</span> <span class="o">=</span> <span class="n">horizon</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">n_samples</span>
  
    <span class="k">def</span> <span class="nf">plan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="s">"""
        Find best action sequence using MPC
        """</span>
        <span class="n">best_action_sequence</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">best_reward</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">'-inf'</span><span class="p">)</span>
      
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span><span class="p">):</span>
            <span class="c1"># Sample action sequence
</span>            <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">horizon</span><span class="p">)</span>
          
            <span class="c1"># Simulate trajectory
</span>            <span class="n">current_state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
          
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                    <span class="k">break</span>
              
                <span class="c1"># Predict next state
</span>                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span>
                    <span class="n">current_state</span><span class="p">,</span> 
                    <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">action</span><span class="p">])</span>
                <span class="p">)</span>
              
                <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span>
              
                <span class="k">if</span> <span class="n">done_pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="bp">True</span>
          
            <span class="c1"># Update best
</span>            <span class="k">if</span> <span class="n">total_reward</span> <span class="o">&gt;</span> <span class="n">best_reward</span><span class="p">:</span>
                <span class="n">best_reward</span> <span class="o">=</span> <span class="n">total_reward</span>
                <span class="n">best_action_sequence</span> <span class="o">=</span> <span class="n">actions</span>
      
        <span class="k">return</span> <span class="n">best_action_sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">best_action_sequence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">run_mpc_agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">n_episodes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="s">"""
    Run MPC agent in environment
    """</span>
    <span class="n">planner</span> <span class="o">=</span> <span class="n">MPCPlanner</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span><span class="p">)</span>
  
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_episodes</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
      
        <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
            <span class="c1"># Plan action
</span>            <span class="n">action</span> <span class="o">=</span> <span class="n">planner</span><span class="p">.</span><span class="n">plan</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
          
            <span class="c1"># Execute action
</span>            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
          
            <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
      
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Episode </span><span class="si">{</span><span class="n">episode</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">, Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Run MPC agent
</span><span class="n">run_mpc_agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">n_episodes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="popular-model-based-rl-algorithms">Popular Model-Based RL Algorithms</h2>

<h3 id="1-pets-probabilistic-ensembles-for-trajectory-shooting">1. PETS (Probabilistic Ensembles for Trajectory Shooting)</h3>

<p>Uses ensemble of probabilistic models for uncertainty-aware planning:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ProbabilisticDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Probabilistic dynamics model with variance prediction
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
      
        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
      
        <span class="c1"># Predict mean and log variance
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">mean_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">logvar_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mean_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">logvar_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>
  
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="s">"""
        Sample next state from learned distribution
        """</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

<span class="k">class</span> <span class="nc">PETSAgent</span><span class="p">:</span>
    <span class="s">"""
    PETS: Probabilistic Ensembles for Trajectory Shooting
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">n_models</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">ProbabilisticDynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">horizon</span> <span class="o">=</span> <span class="n">horizon</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_dim</span>
  
    <span class="k">def</span> <span class="nf">plan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="s">"""
        Plan using trajectory shooting with probabilistic models
        """</span>
        <span class="n">best_action</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">best_reward</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">'-inf'</span><span class="p">)</span>
      
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
            <span class="c1"># Sample action sequence
</span>            <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">horizon</span><span class="p">)</span>
          
            <span class="c1"># Sample model for each step
</span>            <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">current_state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
          
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
                <span class="c1"># Randomly select model
</span>                <span class="n">model_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">))</span>
                <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_idx</span><span class="p">]</span>
              
                <span class="c1"># Sample next state
</span>                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">state_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">current_state</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">state_tensor</span> <span class="o">=</span> <span class="n">current_state</span>
                <span class="n">action_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">action</span><span class="p">]])</span>
              
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">state_tensor</span><span class="p">,</span> <span class="n">action_tensor</span><span class="p">)</span>
                <span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
              
                <span class="c1"># Simple reward (distance to goal)
</span>                <span class="n">total_reward</span> <span class="o">-=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">current_state</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
          
            <span class="k">if</span> <span class="n">total_reward</span> <span class="o">&gt;</span> <span class="n">best_reward</span><span class="p">:</span>
                <span class="n">best_reward</span> <span class="o">=</span> <span class="n">total_reward</span>
                <span class="n">best_action</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      
        <span class="k">return</span> <span class="n">best_action</span>
</code></pre></div></div>

<h3 id="2-mbpo-model-based-policy-optimization">2. MBPO (Model-Based Policy Optimization)</h3>

<p>Combines model-based planning with policy optimization:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MBPOAgent</span><span class="p">:</span>
    <span class="s">"""
    MBPO: Model-Based Policy Optimization
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="c1"># Dynamics model
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">dynamics_model</span> <span class="o">=</span> <span class="n">CartPoleDynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
      
        <span class="c1"># Policy network
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>
      
        <span class="c1"># Value network
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="s">"""
        Get action from policy
        """</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
          
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">action</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>
  
    <span class="k">def</span> <span class="nf">generate_imagined_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real_data</span><span class="p">,</span> <span class="n">n_imagined</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="s">"""
        Generate imagined data using learned model
        """</span>
        <span class="n">imagined_data</span> <span class="o">=</span> <span class="p">[]</span>
      
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_imagined</span><span class="p">):</span>
            <span class="c1"># Sample random state from real data
</span>            <span class="n">sample</span> <span class="o">=</span> <span class="n">real_data</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">real_data</span><span class="p">))]</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">'state'</span><span class="p">]</span>
          
            <span class="c1"># Get action from policy
</span>            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
          
            <span class="c1"># Predict next state using model
</span>            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dynamics_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
          
            <span class="n">imagined_data</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">'state'</span><span class="p">:</span> <span class="n">state</span><span class="p">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="s">'action'</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                <span class="s">'next_state'</span><span class="p">:</span> <span class="n">next_state</span><span class="p">,</span>
                <span class="s">'reward'</span><span class="p">:</span> <span class="n">reward</span><span class="p">,</span>
                <span class="s">'done'</span><span class="p">:</span> <span class="n">done</span>
            <span class="p">})</span>
      
        <span class="k">return</span> <span class="n">imagined_data</span>
  
    <span class="k">def</span> <span class="nf">update_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="s">"""
        Update policy using policy gradient
        """</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
      
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
          
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="mi">32</span><span class="p">):</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">32</span><span class="p">]</span>
              
                <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'state'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
                <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'action'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
                <span class="n">rewards</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s">'reward'</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
              
                <span class="c1"># Get action from policy
</span>                <span class="n">pred_actions</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">policy</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
              
                <span class="c1"># Policy gradient loss (simplified)
</span>                <span class="n">advantage</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">pred_actions</span> <span class="o">*</span> <span class="n">advantage</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)).</span><span class="n">mean</span><span class="p">()</span>
              
                <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="3-dreamer">3. Dreamer</h3>

<p>Model-based RL with learned world model in latent space:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DreamerWorldModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Dreamer-style world model with latent dynamics
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
      
        <span class="c1"># Encoder: observation to latent
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">obs_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Mean and logvar
</span>        <span class="p">)</span>
      
        <span class="c1"># Dynamics: latent transition
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">dynamics</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
      
        <span class="c1"># Decoder: latent to observation
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">obs_dim</span><span class="p">)</span>
        <span class="p">)</span>
      
        <span class="c1"># Reward predictor
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">reward_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
        <span class="s">"""
        Encode observation to latent distribution
        """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>
  
    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent</span><span class="p">):</span>
        <span class="s">"""
        Decode latent to observation
        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">transition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="s">"""
        Predict next latent state
        """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latent</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dynamics</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>
  
    <span class="k">def</span> <span class="nf">predict_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent</span><span class="p">):</span>
        <span class="s">"""
        Predict reward from latent
        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">reward_head</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">sample_latent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
        <span class="s">"""
        Sample latent from observation
        """</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>
  
    <span class="k">def</span> <span class="nf">imagine_trajectory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_obs</span><span class="p">,</span> <span class="n">actions</span><span class="p">):</span>
        <span class="s">"""
        Imagine trajectory from initial observation
        """</span>
        <span class="n">latent</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sample_latent</span><span class="p">(</span><span class="n">initial_obs</span><span class="p">)</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
      
        <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
            <span class="c1"># Transition latent
</span>            <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transition</span><span class="p">(</span><span class="n">latent</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
            <span class="n">latent</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>
          
            <span class="c1"># Predict reward
</span>            <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict_reward</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
            <span class="n">rewards</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
      
        <span class="k">return</span> <span class="n">rewards</span>
</code></pre></div></div>

<h2 id="advantages-and-disadvantages">Advantages and Disadvantages</h2>

<h3 id="advantages-of-model-based-rl">Advantages of Model-Based RL</h3>

<p><strong>Sample Efficiency:</strong></p>

<ul>
  <li>Learn from fewer environment interactions</li>
  <li>Generate synthetic experience using model</li>
  <li>Reuse model across tasks</li>
  <li>Faster convergence</li>
</ul>

<p><strong>Planning:</strong></p>

<ul>
  <li>Look ahead multiple steps</li>
  <li>Optimize actions over horizon</li>
  <li>Handle long-term dependencies</li>
  <li>Better strategic decisions</li>
</ul>

<p><strong>Interpretability:</strong></p>

<ul>
  <li>Learned model is interpretable</li>
  <li>Understand environment dynamics</li>
  <li>Debug and analyze behavior</li>
  <li>Transfer knowledge</li>
</ul>

<h3 id="disadvantages-of-model-based-rl">Disadvantages of Model-Based RL</h3>

<p><strong>Model Bias:</strong></p>

<ul>
  <li>Model errors compound over time</li>
  <li>Inaccuracies lead to poor decisions</li>
  <li>Hard to learn complex dynamics</li>
  <li>Model misspecification</li>
</ul>

<p><strong>Computational Cost:</strong></p>

<ul>
  <li>Planning is computationally expensive</li>
  <li>Need to simulate many trajectories</li>
  <li>Real-time constraints</li>
  <li>Memory requirements</li>
</ul>

<p><strong>Training Complexity:</strong></p>

<ul>
  <li>Need to train both model and policy</li>
  <li>Balance model accuracy and policy performance</li>
  <li>More hyperparameters to tune</li>
  <li>Complex implementation</li>
</ul>

<h2 id="practical-tips">Practical Tips</h2>

<h3 id="1-start-simple">1. Start Simple</h3>

<p>Begin with simple environments and models:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Start with linear model
</span><span class="k">class</span> <span class="nc">LinearDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Progress to neural network
</span><span class="k">class</span> <span class="nc">NNDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
        <span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-use-ensembles">2. Use Ensembles</h3>

<p>Ensemble models reduce uncertainty:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_ensemble</span><span class="p">(</span><span class="n">n_models</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">state_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="s">"""
    Train ensemble of dynamics models
    """</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
  
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">):</span>
        <span class="c1"># Initialize model
</span>        <span class="n">model</span> <span class="o">=</span> <span class="n">CartPoleDynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">)</span>
      
        <span class="c1"># Train on different data subsets
</span>        <span class="n">subset</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">::</span><span class="n">n_models</span><span class="p">]</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">train_cartpole_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">subset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
      
        <span class="n">models</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">models</span>

<span class="k">def</span> <span class="nf">predict_with_ensemble</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
    <span class="s">"""
    Predict with ensemble, return mean and uncertainty
    """</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
  
    <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">predictions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
  
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span>
</code></pre></div></div>

<h3 id="3-balance-real-and-imagined-data">3. Balance Real and Imagined Data</h3>

<p>Combine real and simulated experience:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_mbpo</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">imagined_data</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="s">"""
    Train policy with mix of real and imagined data
    """</span>
    <span class="c1"># Mix data
</span>    <span class="n">n_real</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">)</span>
    <span class="n">n_imagined</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">imagined_data</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_real</span>
  
    <span class="n">mixed_data</span> <span class="o">=</span> <span class="n">real_data</span><span class="p">[:</span><span class="n">n_real</span><span class="p">]</span> <span class="o">+</span> <span class="n">imagined_data</span><span class="p">[:</span><span class="n">n_imagined</span><span class="p">]</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">mixed_data</span><span class="p">)</span>
  
    <span class="c1"># Train on mixed data
</span>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">get_batches</span><span class="p">(</span><span class="n">mixed_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
            <span class="n">update_policy</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">policy</span>
</code></pre></div></div>

<h3 id="4-monitor-model-accuracy">4. Monitor Model Accuracy</h3>

<p>Track model prediction error:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>
    <span class="s">"""
    Evaluate model prediction accuracy
    """</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>
  
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">'state'</span><span class="p">]</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">'action'</span><span class="p">]</span>
        <span class="n">true_next</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">'next_state'</span><span class="p">]</span>
      
        <span class="c1"># Predict
</span>        <span class="n">pred_next</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
      
        <span class="c1"># Compute error
</span>        <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">pred_next</span> <span class="o">-</span> <span class="n">true_next</span><span class="p">)</span>
        <span class="n">errors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
  
    <span class="n">mean_error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
    <span class="n">std_error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
  
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Model error: </span><span class="si">{</span><span class="n">mean_error</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> Â± </span><span class="si">{</span><span class="n">std_error</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean_error</span><span class="p">,</span> <span class="n">std_error</span>
</code></pre></div></div>

<h2 id="testing-the-code">Testing the Code</h2>

<p>Hereâ€™s a comprehensive test script to verify all code examples work correctly:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#!/usr/bin/env python3
</span><span class="s">"""
Test script to verify code in Model-Based RL blog post
"""</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Testing code from Model-Based RL blog post...</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Test 1: GridWorld Environment
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 1: GridWorld Environment"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">GridWorld</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">goal_pos</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">goal_pos</span> <span class="o">=</span> <span class="n">goal_pos</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="mi">4</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">state_space</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">obstacles</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span>
      
        <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">()</span>
      
        <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span><span class="p">)</span>
      
        <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span>
          
            <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">new_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">new_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">new_pos</span> <span class="o">=</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">new_pos</span> <span class="o">=</span> <span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
          
            <span class="k">if</span> <span class="n">new_pos</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">obstacles</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">=</span> <span class="n">new_pos</span>
          
            <span class="n">reward</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">==</span> <span class="bp">self</span><span class="p">.</span><span class="n">goal_pos</span><span class="p">:</span>
                <span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span>
          
            <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">agent_pos</span> <span class="o">==</span> <span class="bp">self</span><span class="p">.</span><span class="n">goal_pos</span>
          
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_state</span><span class="p">(),</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="p">{}</span>
  
    <span class="n">env</span> <span class="o">=</span> <span class="n">GridWorld</span><span class="p">()</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">state</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,),</span> <span class="sa">f</span><span class="s">"Expected shape (2,), got </span><span class="si">{</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)),</span> <span class="sa">f</span><span class="s">"Expected number, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected bool, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">done</span><span class="p">)</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ GridWorld works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— GridWorld failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 2: GridWorldDynamicsModel
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 2: GridWorldDynamicsModel"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">GridWorldDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
      
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">action_onehot</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">4</span><span class="p">)</span>
            <span class="n">action_onehot</span><span class="p">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action</span><span class="p">.</span><span class="nb">long</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action_onehot</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">next_state</span>
      
        <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">integer</span><span class="p">)):</span>
                    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">action</span><span class="p">]])</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
              
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
              
                <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">pred</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>
  
    <span class="n">model</span> <span class="o">=</span> <span class="n">GridWorldDynamicsModel</span><span class="p">()</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">output</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 2), got </span><span class="si">{</span><span class="n">output</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
  
    <span class="n">test_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">test_action</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_state</span><span class="p">,</span> <span class="n">test_action</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pred</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,),</span> <span class="sa">f</span><span class="s">"Expected shape (2,), got </span><span class="si">{</span><span class="n">pred</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ GridWorldDynamicsModel works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— GridWorldDynamicsModel failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 3: RandomShootingPlanner
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 3: RandomShootingPlanner"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">RandomShootingPlanner</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">horizon</span> <span class="o">=</span> <span class="n">horizon</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">n_samples</span>
      
        <span class="k">def</span> <span class="nf">plan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
            <span class="n">best_action</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="n">best_reward</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">'-inf'</span><span class="p">)</span>
          
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span><span class="p">):</span>
                <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">horizon</span><span class="p">)</span>
                <span class="n">current_state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
              
                <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
                    <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
                    <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">next_state</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
                    <span class="n">reward</span> <span class="o">=</span> <span class="o">-</span><span class="n">distance</span>
                    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                    <span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span>
              
                <span class="k">if</span> <span class="n">total_reward</span> <span class="o">&gt;</span> <span class="n">best_reward</span><span class="p">:</span>
                    <span class="n">best_reward</span> <span class="o">=</span> <span class="n">total_reward</span>
                    <span class="n">best_action</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
          
            <span class="k">return</span> <span class="n">best_action</span>
  
    <span class="n">planner</span> <span class="o">=</span> <span class="n">RandomShootingPlanner</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">planner</span><span class="p">.</span><span class="n">plan</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">integer</span><span class="p">)),</span> <span class="sa">f</span><span class="s">"Expected int, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">action</span><span class="p">)</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">action</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Expected action in [0,3], got </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ RandomShootingPlanner works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— RandomShootingPlanner failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 4: CartPoleDynamicsModel
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 4: CartPoleDynamicsModel"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">CartPoleDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">delta_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">reward_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">done_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">delta_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">reward_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">done_head</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">delta</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span>
      
        <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
              
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">action</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
              
                <span class="n">delta</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">state</span> <span class="o">+</span> <span class="n">delta</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">next_state</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">reward</span><span class="p">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">done</span><span class="p">.</span><span class="n">item</span><span class="p">())</span>
  
    <span class="n">model</span> <span class="o">=</span> <span class="n">CartPoleDynamicsModel</span><span class="p">()</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">delta</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">delta</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 4), got </span><span class="si">{</span><span class="n">delta</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">reward</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 1), got </span><span class="si">{</span><span class="n">reward</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">done</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 1), got </span><span class="si">{</span><span class="n">done</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ CartPoleDynamicsModel works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— CartPoleDynamicsModel failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 5: EnsembleDynamicsModel
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 5: EnsembleDynamicsModel"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">EnsembleDynamicsModel</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_models</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">state_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">CartPoleDynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">)</span>
            <span class="p">]</span>
      
        <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">:</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
                <span class="n">predictions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="n">pred</span><span class="p">)</span>
            <span class="n">predictions_array</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
            <span class="n">mean_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions_array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">std_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">predictions_array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mean_pred</span><span class="p">,</span> <span class="n">std_pred</span>
  
    <span class="n">ensemble</span> <span class="o">=</span> <span class="n">EnsembleDynamicsModel</span><span class="p">(</span><span class="n">n_models</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">ensemble</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">mean</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">4</span><span class="p">,),</span> <span class="sa">f</span><span class="s">"Expected shape (4,), got </span><span class="si">{</span><span class="n">mean</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">std</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">4</span><span class="p">,),</span> <span class="sa">f</span><span class="s">"Expected shape (4,), got </span><span class="si">{</span><span class="n">std</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ EnsembleDynamicsModel works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— EnsembleDynamicsModel failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 6: ProbabilisticDynamicsModel
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 6: ProbabilisticDynamicsModel"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">ProbabilisticDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mean_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">logvar_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
      
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mean_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">logvar_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>
      
        <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>
  
    <span class="n">model</span> <span class="o">=</span> <span class="n">ProbabilisticDynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">mean</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 4), got </span><span class="si">{</span><span class="n">mean</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">logvar</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 4), got </span><span class="si">{</span><span class="n">logvar</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">sample</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 4), got </span><span class="si">{</span><span class="n">sample</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ ProbabilisticDynamicsModel works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— ProbabilisticDynamicsModel failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 7: DreamerWorldModel
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 7: DreamerWorldModel"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">DreamerWorldModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">obs_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">dynamics</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">obs_dim</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">reward_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      
        <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>
      
        <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
      
        <span class="k">def</span> <span class="nf">transition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latent</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dynamics</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>
      
        <span class="k">def</span> <span class="nf">predict_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">reward_head</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
      
        <span class="k">def</span> <span class="nf">sample_latent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>
  
    <span class="n">model</span> <span class="o">=</span> <span class="n">DreamerWorldModel</span><span class="p">(</span><span class="n">obs_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  
    <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">mean</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 16), got </span><span class="si">{</span><span class="n">mean</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
  
    <span class="n">latent</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">sample_latent</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">latent</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 16), got </span><span class="si">{</span><span class="n">latent</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
  
    <span class="n">next_mean</span><span class="p">,</span> <span class="n">next_logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transition</span><span class="p">(</span><span class="n">latent</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">next_mean</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 16), got </span><span class="si">{</span><span class="n">next_mean</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
  
    <span class="n">reward</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_reward</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">reward</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 1), got </span><span class="si">{</span><span class="n">reward</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
  
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">decoded</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 10), got </span><span class="si">{</span><span class="n">decoded</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
  
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ DreamerWorldModel works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— DreamerWorldModel failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test 8: LinearDynamicsModel
</span><span class="k">print</span><span class="p">(</span><span class="s">"Test 8: LinearDynamicsModel"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">LinearDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
      
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  
    <span class="n">model</span> <span class="o">=</span> <span class="n">LinearDynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">output</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Expected shape (1, 4), got </span><span class="si">{</span><span class="n">output</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"âœ“ LinearDynamicsModel works correctly</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"âœ— LinearDynamicsModel failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"All tests passed! âœ“"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">The code in blog post is syntactically correct"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"and should work as expected."</span><span class="p">)</span>
</code></pre></div></div>

<p>To run this test script, save it as <code class="language-plaintext highlighter-rouge">test_modelbased_code.py</code> and execute:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python test_modelbased_code.py
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>Model-Based Reinforcement Learning offers a powerful approach to learning efficient policies by understanding environment dynamics. By learning models of the world and using them for planning, we can achieve sample-efficient learning and better long-term decision-making.</p>

<h3 id="key-takeaways">Key Takeaways</h3>

<ol>
  <li><strong>Learn Dynamics Models:</strong> Train neural networks to predict state transitions</li>
  <li><strong>Use Planning:</strong> Employ MPC, CEM, or other planning algorithms</li>
  <li><strong>Handle Uncertainty:</strong> Use ensembles and probabilistic models</li>
  <li><strong>Balance Real/Simulated:</strong> Mix real and imagined experience</li>
  <li><strong>Start Simple:</strong> Begin with linear models, progress to neural networks</li>
</ol>

<h3 id="future-directions">Future Directions</h3>

<ul>
  <li><strong>Better World Models:</strong> More accurate and generalizable models</li>
  <li><strong>Sample Efficient Methods:</strong> Learn from even fewer interactions</li>
  <li><strong>Uncertainty Quantification:</strong> Better handling of model uncertainty</li>
  <li><strong>Hierarchical Planning:</strong> Multi-level planning for complex tasks</li>
  <li><strong>Meta-Learning:</strong> Learn to learn models quickly</li>
</ul>

<h3 id="resources">Resources</h3>

<ul>
  <li><strong>Libraries:</strong> mbrl-lib, garage, rlpyt</li>
  <li><strong>Simulators:</strong> MuJoCo, PyBullet, Isaac Gym</li>
</ul>

<p>Happy model-based learning!</p>


          <!-- Syntax Highlighting -->
          <link href="/assets/css/syntax.css" rel="stylesheet">
          <script src="/assets/scripts/copyCode.js" async></script>

          <!-- Ads -->
          <section aria-label="Advertisements" class="ads mt-4">
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
            <ins class="adsbygoogle"
                 style="display:block"
                 data-ad-client="ca-pub-2976211678184829"
                 data-ad-slot="7658460605"
                 data-ad-format="auto"
                 data-full-width-responsive="true"></ins>
            <script>
              (adsbygoogle = window.adsbygoogle || []).push({});
            </script>
          </section>

        </article>

      </div>

      <!-- Post Navigation -->
      <nav class="post-navigation controls__inner mt-5" aria-label="Post navigation">
        <div class="controls__item prev">
          
            <span>Previous</span>
            <a href="/Reinforcement-Learning-for-Robotics/" rel="prev">
              Reinforcement Learning for Robotics -...
            </a>
          
        </div>

        <div class="controls__item next">
          
        </div>
      </nav>

      <!-- Related Posts -->
      
      
      
      
      
      
      
      
      
      
        <section class="related-posts mt-5" aria-label="Related Posts">
          <div class="container">
            <h2 class="related-posts__title">Related Posts</h2>
            <div class="related-posts__grid">
              
                <a class="related-post-card" href="/Introduction-to-Reinforcement-Learning/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Part 1: Introduction to Reinforcement Learning - Core Concepts and Fundamentals"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Part 1: Introduction to Reinforcement Learning - Core Con...</h3>
                    <p class="related-post-card__excerpt">
                      
                        Part 1: Introduction to Reinforcement Learning - Core Concepts and Fundamentals Welcome to first post...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 01, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/Reinforcement-Learning-for-Robotics/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Reinforcement Learning for Robotics - Real-World Robot Control"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Reinforcement Learning for Robotics - Real-World Robot Co...</h3>
                    <p class="related-post-card__excerpt">
                      
                        Reinforcement Learning for Robotics - Real-World Robot Control Welcome to our comprehensive guide on Reinforcement...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 18, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/Advanced-Topics-Future-Directions-RL/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Part 12: Advanced Topics & Future Directions in RL - Series Conclusion"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Part 12: Advanced Topics & Future Directions in RL - Seri...</h3>
                    <p class="related-post-card__excerpt">
                      
                        Part 12: Advanced Topics &amp; Future Directions in RL - Series Conclusion Welcome to the...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 12, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/Deep-Q-Networks-DQN/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Part 4: Deep Q-Networks (DQN) - Neural Networks for Reinforcement Learning"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Part 4: Deep Q-Networks (DQN) - Neural Networks for Reinf...</h3>
                    <p class="related-post-card__excerpt">
                      
                        Part 4: Deep Q-Networks (DQN) - Neural Networks for Reinforcement Learning Welcome to the fourth...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 04, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/Game-AI-Reinforcement-Learning/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Part 11: Game AI with Reinforcement Learning - Build Intelligent Game Agents"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Part 11: Game AI with Reinforcement Learning - Build Inte...</h3>
                    <p class="related-post-card__excerpt">
                      
                        Part 11: Game AI with Reinforcement Learning - Build Intelligent Game Agents Welcome to the...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 11, 2026
                    </span>
                  </div>
                </a>
              
                <a class="related-post-card" href="/Proximal-Policy-Optimization-PPO/">
                  
                    <div class="related-post-card__image">
                      <img src="https://www.pyshine.com/assets/img/posts/2026-feb-deeprl/2026-feb-deeprl_thumb.jpg" 
                           alt="Part 7: Proximal Policy Optimization (PPO) - State-of-the-Art RL Algorithm"
                           loading="lazy" />
                    </div>
                  
                  <div class="related-post-card__content">
                    <h3 class="related-post-card__title">Part 7: Proximal Policy Optimization (PPO) - State-of-the...</h3>
                    <p class="related-post-card__excerpt">
                      
                        Part 7: Proximal Policy Optimization (PPO) - State-of-the-Art RL Algorithm Welcome to the seventh post...
                      
                    </p>
                    <span class="related-post-card__date">
                      Feb 07, 2026
                    </span>
                  </div>
                </a>
              
            </div>
          </div>
        </section>
      

      <!-- Disqus -->
      
        <section class="comments mt-5" aria-label="Comments Section">
          
<section class="comments mt-5" aria-label="Comments Section" style="text-align: center; padding: 50px 0; background-color: #fafafa;">
  <div id="disqus_thread" style="max-width: 800px; margin: 0 auto;"></div>
  <script>

var disqus_config = function () {
this.page.url = 'https://pyshine.com/Model-Based-RL/';
this.page.identifier = 'https://pyshine.com/Model-Based-RL/';
};

(function() {
var d = document, s = d.createElement('script');
s.src = 'https://https-py2ai-github-io.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the comments.</noscript>
</section>


        </section>
      

    </main>

    <footer class="footer">
  <div class="container">
    <nav class="social">
      
      
      
    </nav>
    <span>&copy; 2026 PyShine. All rights reserved.</span>
  </div>
</footer>
<script async src="/assets/js/bundle.js"></script>

<script async>
  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.register('/sw.js').then(function( registration ) {
      console.log('ServiceWorker registration successful with scope: ', registration.scope);
    })
    .catch(function(error) {
      console.log('ServiceWorker registration failed: ', error);
    });
  }
</script>



    <!-- Back to Top Button -->
    <button id="back-to-top" class="back-to-top" aria-label="Back to top">
      <svg viewBox="0 0 24 24" width="24" height="24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <polyline points="18 15 12 9 6 15"></polyline>
      </svg>
    </button>

    <!-- MathJax -->
    


    <!-- Ads -->
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

    <!-- SIDEBAR TOC SCRIPT -->
    <script>
    document.addEventListener("DOMContentLoaded", function() {
      const toc = document.getElementById("toc-list");
      const headings = document.querySelectorAll(
        ".post-content h2:not(.no-toc), .post-content h3:not(.no-toc)"
      );
      if (!toc || headings.length === 0) return;

      const ul = document.createElement("ul");
      headings.forEach(h => {
        const id = h.id || h.textContent.trim().toLowerCase().replace(/\s+/g, "-");
        h.id = id;

        const li = document.createElement("li");
        if (h.tagName === "H3") li.style.marginLeft = "1rem";

        li.innerHTML = `<a href="#${id}">${h.textContent}</a>`;
        ul.appendChild(li);
      });
      toc.appendChild(ul);
    });
    </script>

    <!-- INLINE TOC SCRIPT -->
    <script>
    document.addEventListener("DOMContentLoaded", function() {
      const tocTarget = document.getElementById("inline-toc-list");
      const headings = document.querySelectorAll(
        ".post-content h2:not(.no-toc), .post-content h3:not(.no-toc)"
      );
      if (!tocTarget || headings.length === 0) return;

      const ul = document.createElement("ul");
      headings.forEach(h => {
        const id = h.id || h.textContent.trim().toLowerCase().replace(/\s+/g, "-");
        h.id = id;

        const li = document.createElement("li");
        if (h.tagName === "H3") li.style.marginLeft = "1rem";

        li.innerHTML = `<a href="#${id}">${h.textContent}</a>`;
        ul.appendChild(li);
      });
      tocTarget.appendChild(ul);
    });
    </script>

    <!-- Back to Top Button Script -->
    <script>
    document.addEventListener("DOMContentLoaded", function() {
      const backToTopButton = document.getElementById("back-to-top");
      if (!backToTopButton) return;

      // Show button when scrolled down 300px
      window.addEventListener("scroll", function() {
        if (window.pageYOffset > 300) {
          backToTopButton.classList.add("visible");
        } else {
          backToTopButton.classList.remove("visible");
        }
      });

      // Smooth scroll to top when clicked
      backToTopButton.addEventListener("click", function() {
        window.scrollTo({
          top: 0,
          behavior: "smooth"
        });
      });
    });
    </script>

    <!-- INLINE TOC STYLES -->
    <style>
      .inline-toc-box {
        background: #D4EDFD;
        padding: 15px 20px;
        border-radius: 10px;
        margin-bottom: 25px;
        border: 1px solid #e0e0e0;
      }
      .inline-toc-box ul {
        margin: 0;
        padding-left: 18px;
      }
      .inline-toc-box li {
        margin-bottom: 6px;
      }
      /* Center post navigation */
      .post-navigation.controls__inner {
        justify-content: center !important;
        gap: 4rem;
      }
      /* Related Posts Styles */
      .related-posts {
        margin-top: 3rem;
        padding: 2rem 0;
        border-top: 1px solid #e0e0e0;
      }
      .related-posts .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 0 1rem;
      }
      .related-posts__title {
        font-size: 1.75rem;
        margin-bottom: 1.5rem;
        color: #000000;
        text-align: center;
      }
      .related-posts__grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 1.5rem;
        max-width: 1200px;
        margin: 0 auto;
      }
      .related-post-card {
        display: block;
        text-decoration: none;
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        overflow: hidden;
        transition: box-shadow 0.3s ease, transform 0.3s ease;
      }
      .related-post-card:hover {
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        transform: translateY(-4px);
      }
      .related-post-card__image {
        width: 100%;
        height: 100px;
        background: #f5f5f5;
      }
      .related-post-card__image img {
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      .related-post-card__content {
        padding: 0.75rem;
      }
      .related-post-card__title {
        font-size: 0.95rem;
        margin: 0 0 0.4rem 0;
        color: #000000;
        line-height: 1.3;
        font-weight: 600;
      }
      .related-post-card__excerpt {
        font-size: 0.8rem;
        color: #666;
        margin: 0 0 0.5rem 0;
        line-height: 1.4;
      }
      .related-post-card__date {
        font-size: 0.75rem;
        color: #999;
      }
      @media (max-width: 992px) {
        .related-posts__grid {
          grid-template-columns: repeat(2, 1fr);
        }
      }
      @media (max-width: 600px) {
        .related-posts__grid {
          grid-template-columns: 1fr;
        }
      }
      /* Back to Top Button Styles */
      .back-to-top {
        position: fixed;
        bottom: 30px;
        right: 30px;
        width: 50px;
        height: 50px;
        background: #000000;
        color: #ffffff;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        opacity: 0;
        visibility: hidden;
        transform: translateY(20px);
        transition: all 0.3s ease;
        z-index: 9999;
      }
      .back-to-top.visible {
        opacity: 1;
        visibility: visible;
        transform: translateY(0);
      }
      .back-to-top:hover {
        background: #333333;
        box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
        transform: translateY(-2px);
      }
      .back-to-top:active {
        transform: translateY(0);
      }
      @media (max-width: 768px) {
        .back-to-top {
          bottom: 20px;
          right: 20px;
          width: 45px;
          height: 45px;
        }
      }
    </style>

  </body>
</html>


