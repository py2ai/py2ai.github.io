

  <!DOCTYPE html>
<html lang="en" itemscope itemtype="https://schema.org/Article">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Pinterest & Google verification -->
  <meta name="p:domain_verify" content="fb68a8459fe32b8b072bcd5cc620d125"/>
  <meta name="google-site-verification" content="WAkFPi5cvufClnQetgIl0STmvvwHhVf8jfyENFWhsxU" />
  <meta name="google-site-verification" content="g2pFZlv-92XQD67BPgiVHsvZ4TZH13Ucvmmvvv36kU4" />

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How to make a chatGPT like application | PyShine</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="How to make a chatGPT like application" />
<meta name="author" content="PyShine Team" />
<meta property="og:locale" content="en" />
<meta name="description" content="In this tutorial we will learn to compress GPT and make a working chat GPT app" />
<meta property="og:description" content="In this tutorial we will learn to compress GPT and make a working chat GPT app" />
<link rel="canonical" href="http://localhost:4000/How-to-make-chat-GPT-like-application/" />
<meta property="og:url" content="http://localhost:4000/How-to-make-chat-GPT-like-application/" />
<meta property="og:site_name" content="PyShine" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-02-23T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How to make a chatGPT like application" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"PyShine Team"},"dateModified":"2023-02-23T00:00:00+08:00","datePublished":"2023-02-23T00:00:00+08:00","description":"In this tutorial we will learn to compress GPT and make a working chat GPT app","headline":"How to make a chatGPT like application","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/How-to-make-chat-GPT-like-application/"},"name":"{{ page.title escape }}","url":"http://localhost:4000/How-to-make-chat-GPT-like-application/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Favicon & App Icons -->
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/img/icons/apple-touch-icon.png?v=qA3OXqyw77">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/icons/favicon-32x32.png?v=qA3OXqyw77">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/img/icons/favicon-16x16.png?v=qA3OXqyw77">
  <link rel="manifest" href="/assets/img/icons/manifest.json?v=qA3OXqyw77">
  <link rel="mask-icon" href="/assets/img/icons/safari-pinned-tab.svg?v=qA3OXqyw77" color="#5bbad5">
  <link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77">
  <!--[if IE]><link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77"><![endif]-->

  <!-- App & Theme Info -->
  <meta name="apple-mobile-web-app-title" content="Sleek">
  <meta name="application-name" content="Sleek">
  <meta name="msapplication-config" content="/assets/img/icons/browserconfig.xml?v=qA3OXqyw77">
  <meta name="theme-color" content="#ffffff">

  
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-TCVFBKF"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'GTM-TCVFBKF');
</script>

  

  <!-- Critical CSS Inline -->
  <style class="inlineCSS">
    h1{color:#313237;margin-top:0;margin-bottom:.5rem}.dark-bg{background-color:#19d319}@media (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:last-of-type,.post-card:nth-child(2n+2){margin-right:0}}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figure,main{display:block}figure{margin:1em 40px}a{background-color:transparent;-webkit-text-decoration-skip:objects}img{border-style:none}svg:not(:root){overflow:hidden}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}body{-webkit-overflow-scrolling:touch}*,::after,::before{-webkit-box-sizing:inherit;box-sizing:inherit}.site{display:-webkit-box;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.site__content{-webkit-box-flex:1;-ms-flex:1;flex:1}img{max-width:100%;height:auto;width:auto;vertical-align:middle}figure{margin:0}body{background-color:#fff;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Hiragino Sans GB","Microsoft YaHei","WenQuanYi Micro Hei",sans-serif;font-size:1rem;line-height:1.5;color:#343851;-webkit-font-smoothing:antialiased;-webkit-text-size-adjust:100%}p{margin-top:0;margin-bottom:1.25rem}h1,h2{color:#313237;margin-top:0;margin-bottom:.5rem}a{color:#277cea;text-decoration:none;border-bottom:1px dashed #277cea}.blur{background:#fff;filter:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg"><filter id="filter"><feGaussianBlur stdDeviation="16" /></filter></svg>#filter');-webkit-filter:blur(1rem);filter:blur(1rem)}.container{padding:0 20px}@media (min-width:0){.container{max-width:auto;margin:0 auto}}@media (min-width:36em){.container{max-width:540px;margin:0 auto}}@media (min-width:48em){.container{max-width:720px;margin:0 auto}}@media (min-width:62em){.container{max-width:960px;margin:0 auto}}@media (min-width:75em){.container{max-width:1170px;margin:0 auto}}.header{background-color:#fff;color:#343851;position:absolute;z-index:4;width:100%;top:0;left:0;will-change:transform;-webkit-transform:translateY(0);transform:translateY(0)}.header a{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-bottom:0}.header__logo{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;overflow:hidden;padding:19px 0;margin-right:1.25rem;outline:0;border-bottom:0;color:#313237}.header__logo .header__logo--container{width:58px}.header__logo .header__logo--container .logo{fill:currentColor}.header__inner{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:3.75em;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.header__links{padding-bottom:.5rem;display:none;position:absolute;top:3.75em;left:0;width:100%;height:auto;background:#fff}.header__link{color:#343851;padding:.938rem 0;border-top:1px solid #ededed}.header__toggle{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;width:44px;height:100%;background-color:transparent;padding-left:1.25rem}.header__toggle span{display:block;position:relative;margin-top:4px;background-color:#343851;width:100%;height:2px;border-radius:1px}.header__toggle span:first-child{margin-top:0}@media (min-width:62em){.header__toggle{display:none;visibility:hidden}.header__links{position:static;padding:0;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;visibility:visible;width:auto;height:100%}.header__links-wrapper{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;padding:0}.header__link{position:relative;padding:.938rem 1rem;border:0;height:100%}.header__link::after{content:"";display:block;position:absolute;left:0;bottom:0;height:3px;width:100%;-webkit-transform:scaleX(0);transform:scaleX(0);background:#277cea}}.post-card{display:block;position:relative;width:100%;min-height:250px;border-radius:4px;overflow:hidden;background-color:#fff;-webkit-box-shadow:0 1px 3px rgba(0,0,0,.08);box-shadow:0 1px 3px rgba(0,0,0,.08);margin-bottom:2.25rem;border-bottom:0}@media (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:0}}@media (min-width:75em){.post-card{width:31.25%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:3.125%}}.post-card__label{position:absolute;top:1.5rem;left:1.5rem;z-index:2}.post-card__thumb{margin:0;background:#fff;position:relative;overflow:hidden}.post-card__thumb::after{content:"";display:block;height:0;width:100%;padding-bottom:56.25%}.post-card__thumb>*{position:absolute;top:0;left:0;width:100%;height:100%;display:block}.post-card__inner{padding:1.875rem 1.25rem .625rem;color:#838c8d}.post-card__header{margin-bottom:.75rem}.post-card__header .post-card__meta{font-size:.875rem}.label{padding:0 10px;margin-bottom:1rem;display:inline-block;line-height:20px;font-size:.75rem;text-transform:uppercase;letter-spacing:1px;color:rgba(255,255,255,.8);border:2px solid rgba(255,255,255,.5);border-radius:100px}.hero{margin:3.75rem auto 0;min-height:16.25rem;width:100%;position:relative;background-color:#dde5ea;background-repeat:no-repeat;background-position:50%;background-size:cover}@media (min-width:62em){.hero{margin:0 auto;height:36em}}.hero::before{position:absolute;display:block;content:"";top:0;left:0;width:100%;height:100%;background:rgba(52,56,81,.8)}.hero__wrap{position:absolute;margin:auto;top:50%;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);text-align:center;color:rgba(255,255,255,.8);width:100%;max-width:90%;z-index:1}.hero__wrap .hero__title{font-size:1.8em;color:#fff}.blog{background-color:#f9f9f9}.post-list{padding-top:2.5em;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-flex:1;-ms-flex:1 0 auto;flex:1 0 auto}@media (min-width:48em){.hero__wrap{max-width:40em}.hero__wrap .hero__title{padding:1rem 0;font-size:2.625em;line-height:3.125rem}.post-list{padding-top:5em}}
  </style>

  <!-- Main CSS -->
  <link rel="preload" href="/assets/css/main.css" as="style" onload="this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="/assets/css/main.css"></noscript>

  <script type="text/javascript">
    /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
(function(w){"use strict";if(!w.loadCSS){w.loadCSS=function(){}}
var rp=loadCSS.relpreload={};rp.support=(function(){var ret;try{ret=w.document.createElement("link").relList.supports("preload")}catch(e){ret=!1}
return function(){return ret}})();rp.bindMediaToggle=function(link){var finalMedia=link.media||"all";function enableStylesheet(){link.media=finalMedia}
if(link.addEventListener){link.addEventListener("load",enableStylesheet)}else if(link.attachEvent){link.attachEvent("onload",enableStylesheet)}
setTimeout(function(){link.rel="stylesheet";link.media="only x"});setTimeout(enableStylesheet,3000)};rp.poly=function(){if(rp.support()){return}
var links=w.document.getElementsByTagName("link");for(var i=0;i<links.length;i++){var link=links[i];if(link.rel==="preload"&&link.getAttribute("as")==="style"&&!link.getAttribute("data-loadcss")){link.setAttribute("data-loadcss",!0);rp.bindMediaToggle(link)}}};if(!rp.support()){rp.poly();var run=w.setInterval(rp.poly,500);if(w.addEventListener){w.addEventListener("load",function(){rp.poly();w.clearInterval(run)})}else if(w.attachEvent){w.attachEvent("onload",function(){rp.poly();w.clearInterval(run)})}}
if(typeof exports!=="undefined"){exports.loadCSS=loadCSS}
else{w.loadCSS=loadCSS}}(typeof global!=="undefined"?global:this))

  </script>

  <!-- MathJax -->
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>


  <body class="site" itemscope itemtype="https://schema.org/WebPage">

    
      <!-- Google Tag Manager (noscript) -->
      <noscript>
        <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TCVFBKF"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
      </noscript>
      <!-- End Google Tag Manager -->
    

    <header class="header" itemscope itemtype="http://schema.org/SiteNavigationElement" aria-label="Main navigation">
  <div class="container">
    <div class="header__inner">
      <!-- Logo -->
      <a class="header__logo" href="/">
        <div class="header__logo--container">
          <?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 16.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24" xml:space="preserve">
<g>
	<path d="M18.121,9.88l-7.832-7.836c-0.155-0.158-0.428-0.155-0.584,0L1.842,9.913c-0.262,0.263-0.073,0.705,0.292,0.705h2.069v7.042c0,0.227,0.187,0.414,0.414,0.414h3.725c0.228,0,0.414-0.188,0.414-0.414v-3.313h2.483v3.313c0,0.227,0.187,0.414,0.413,0.414h3.726c0.229,0,0.414-0.188,0.414-0.414v-7.042h2.068h0.004C18.331,10.617,18.389,10.146,18.121,9.88 M14.963,17.245h-2.896v-3.313c0-0.229-0.186-0.415-0.414-0.415H8.342c-0.228,0-0.414,0.187-0.414,0.415v3.313H5.032v-6.628h9.931V17.245z M3.133,9.79l6.864-6.868l6.867,6.868H3.133z"></path>

	
	
</g>
</svg>

        </div>
      </a>

      <!-- Navigation Links -->
      <nav class="header__links">
        <div class="container header__links-wrapper">
          
            <a class="header__link" href="/" itemprop="url">
              <span itemprop="name">Home</span>
            </a>
          
            <a class="header__link" href="/converter.html" itemprop="url">
              <span itemprop="name">Free PNG Converter</span>
            </a>
          
            <a class="header__link" href="/categories" itemprop="url">
              <span itemprop="name">Categories</span>
            </a>
          
            <a class="header__link" href="/about" itemprop="url">
              <span itemprop="name">About</span>
            </a>
          
            <a class="header__link" href="/contact" itemprop="url">
              <span itemprop="name">Contact</span>
            </a>
          
            <a class="header__link" href="/privacy" itemprop="url">
              <span itemprop="name">Privacy Policy</span>
            </a>
          
            <a class="header__link" href="/disclaimer" itemprop="url">
              <span itemprop="name">Disclaimer</span>
            </a>
          
        </div>
      </nav>

      <!-- Mobile Menu Toggle -->
      <div class="header__toggle" aria-label="Toggle navigation">
        <span></span>
        <span></span>
        <span></span>
      </div>
    </div>
  </div>

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How to make a chatGPT like application | PyShine</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="How to make a chatGPT like application" />
<meta name="author" content="PyShine Team" />
<meta property="og:locale" content="en" />
<meta name="description" content="In this tutorial we will learn to compress GPT and make a working chat GPT app" />
<meta property="og:description" content="In this tutorial we will learn to compress GPT and make a working chat GPT app" />
<link rel="canonical" href="http://localhost:4000/How-to-make-chat-GPT-like-application/" />
<meta property="og:url" content="http://localhost:4000/How-to-make-chat-GPT-like-application/" />
<meta property="og:site_name" content="PyShine" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-02-23T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How to make a chatGPT like application" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"PyShine Team"},"dateModified":"2023-02-23T00:00:00+08:00","datePublished":"2023-02-23T00:00:00+08:00","description":"In this tutorial we will learn to compress GPT and make a working chat GPT app","headline":"How to make a chatGPT like application","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/How-to-make-chat-GPT-like-application/"},"name":"{{ page.title escape }}","url":"http://localhost:4000/How-to-make-chat-GPT-like-application/"}</script>
<!-- End Jekyll SEO tag -->

</header>


    
      <div class="hero dark-bg" role="img" aria-label="How to make a chatGPT like application">
    
        <div class="hero__wrap">
          
            <div class="hero__categories">
              
            </div>
          

          <h1 class="hero__title" itemprop="headline">How to make a chatGPT like application</h1>

          <p class="hero__meta">
            <time datetime="2023-02-23T00:00:00+08:00" itemprop="datePublished">
              23 Feb 2023
            </time>
            &nbsp;·&nbsp;
            
            <span itemprop="timeRequired">
              
                12 mins read
              
            </span>
          </p>
        </div>
      </div>

    <main class="site__content" role="main">
      <div class="container">

        <article class="post-content"
                 itemprop="articleBody"
                 itemscope itemtype="https://schema.org/Article">
          
          <p>Hello friends! Yes, it is possible to make a chat GPT like application by compressing the GPT models to reduce their size and computational complexity. Model compression techniques can be used to reduce the number of parameters and operations required by the model without significantly impacting its performance. But before that let’s see what is GPT?</p>

<h1 id="gpt-generative-pre-trained-transformer">GPT (Generative Pre-trained Transformer)</h1>

<p>GPT (Generative Pre-trained Transformer) model consist of following components:</p>

<ul>
  <li>
    <p>Transformer architecture: GPT models are built using the Transformer architecture, which is a type of neural network that excels at processing sequences of variable length. The Transformer architecture is composed of multiple layers of self-attention and feedforward networks, which allows the model to attend to different parts of the input sequence and learn complex relationships between them.</p>
  </li>
  <li>
    <p>Pre-training task: GPT models are typically pre-trained on a large corpus of text using a language modeling objective, such as predicting the next word in a sequence given the previous words. Pre-training helps the model learn general language patterns and structures that can be fine-tuned for downstream tasks.</p>
  </li>
  <li>
    <p>Fine-tuning layers: After pre-training, the GPT model can be fine-tuned on a specific downstream task, such as text classification, question answering, or text generation. Fine-tuning involves adding task-specific layers on top of the pre-trained model and updating the model parameters on task-specific data.</p>
  </li>
  <li>
    <p>Embedding layer: The input to a GPT model is typically encoded as a sequence of tokens, which are converted into dense vector representations using an embedding layer. The embedding layer maps each token to a continuous vector space, which allows the model to capture the semantic relationships between the tokens.</p>
  </li>
  <li>
    <p>Positional encoding: The Transformer architecture does not inherently capture the order of the input sequence, so GPT models use a positional encoding scheme to incorporate positional information into the model. Positional encoding adds a learnable vector to each input token that encodes its position in the sequence.</p>
  </li>
  <li>
    <p>Vocabulary and tokenization: GPT models operate on a fixed vocabulary of tokens, which are typically selected based on their frequency in the training corpus. Text input is preprocessed by tokenizing it into a sequence of these vocabulary tokens, which are then fed into the GPT model.</p>
  </li>
  <li>
    <p>Together, these components allow GPT models to process and generate natural language text, making them powerful tools for a wide range of natural language processing tasks.</p>
  </li>
</ul>

<p>There are various approaches to compressing GPT models, including:</p>

<ul>
  <li>
    <p>Pruning: This involves removing the least important parameters from the model, based on their magnitude or sensitivity to perturbations. Pruning can significantly reduce the size of the model while preserving its accuracy.</p>
  </li>
  <li>
    <p>Quantization: This involves reducing the precision of the model’s weights and activations, such as converting them from 32-bit floating point to 16-bit or 8-bit integers. This reduces the model’s memory and computation requirements, but may slightly reduce its accuracy.</p>
  </li>
  <li>
    <p>Knowledge distillation: This involves training a smaller model to mimic the behavior of a larger, more complex model. The smaller model is trained using the larger model’s predictions as targets, which allows it to learn from the larger model’s knowledge. This can result in a smaller model with comparable performance to the larger one.</p>
  </li>
  <li>
    <p>Low-rank factorization: This involves decomposing the weight matrices of the model into lower-rank matrices, which reduces the number of parameters and computations required. This can be achieved using techniques such as singular value decomposition (SVD) or tensor decomposition.</p>
  </li>
  <li>
    <p>Grouped convolutions: This involves grouping the input and output channels of convolutional layers, which can reduce the number of parameters and computations required while preserving the spatial relationships between the features.</p>
  </li>
</ul>

<p>Overall, model compression techniques can help reduce the computational and memory requirements of GPT models, making them more efficient and practical for deployment in resource-constrained environments.</p>

<h1 id="lets-use-flexgen-to-make-a-chat-gpt-application">Let’s use FlexGen to make a chat GPT application</h1>

<h2 id="what-is-flexgen">What is FlexGen</h2>

<p>FlexGen is a method for compressing GPT (Generative Pre-trained Transformer) models, which was proposed in a research paper published by Facebook AI in 2021. The goal of FlexGen is to reduce the computational cost and memory footprint of GPT models without significantly affecting their performance.</p>

<p>FlexGen is based on the idea of dynamically adjusting the model’s architecture during inference based on the input sequence length. In traditional GPT models, the maximum sequence length is fixed during training and inference, which can lead to high computational and memory costs for long sequences. FlexGen addresses this issue by dividing the model into multiple stages, each optimized for a specific range of sequence lengths. During inference, FlexGen selects the appropriate stage based on the length of the input sequence, and only computes the necessary layers for that stage. This reduces the computational and memory cost compared to a traditional GPT model that computes all layers for every input sequence.</p>

<p>FlexGen also incorporates other model compression techniques such as weight pruning, quantization, and knowledge distillation to further reduce the size and computational cost of the model. Experimental results show that FlexGen can achieve significant speedup and memory savings compared to traditional GPT models, while maintaining similar or slightly improved performance on various language modeling benchmarks.</p>

<h1 id="make-the-simple-chat-gpt-like-application">Make the simple chat GPT like application</h1>

<h2 id="step-1-make-a-miniconda-environment-for-python-38">Step 1. Make a miniconda environment for python 3.8</h2>

<p>Download the appropriate version of Miniconda for your operating system from the official website: https://docs.conda.io/en/latest/miniconda.html</p>

<p>Install Miniconda by running the installer and following the on-screen instructions.</p>

<p>Open a terminal or command prompt and check that conda is installed and available in your path by running the command:</p>

<p><code class="language-plaintext highlighter-rouge">conda --version</code></p>

<p>Create a new Python 3.8 environment by running the following command:</p>

<p><code class="language-plaintext highlighter-rouge">conda create --name myenv python=3.8</code></p>

<p>Replace <code class="language-plaintext highlighter-rouge">myenv</code> with the name you want to give your new environment. You can choose any name you like.</p>

<p>Activate the new environment by running the following command:</p>

<p><code class="language-plaintext highlighter-rouge">conda activate myenv</code></p>

<p>Again, replace <code class="language-plaintext highlighter-rouge">myenv</code> with the name of your environment.</p>

<p>Now you can install packages and work with your Python 3.8 environment. For example, you can install NumPy by running the command:</p>

<p><code class="language-plaintext highlighter-rouge">conda install numpy</code></p>

<p>This will install the latest version of NumPy in your environment.</p>

<p>When you’re done working in your environment, you can deactivate it by running the following command:</p>

<p><code class="language-plaintext highlighter-rouge">conda deactivate</code></p>

<p>This will return you to your base environment.</p>

<p>That’s it! You now have Miniconda installed and a new Python 3.8 environment set up. You can create additional environments in the same way, each with its own set of packages and Python version.</p>

<h2 id="step-2-install-the-flexgen">Step 2. Install the FlexGen</h2>

<p>First of all activate the conda environment <code class="language-plaintext highlighter-rouge">conda activate myenv</code> for the python3.8.</p>

<p>Download the FlexGen repo and install by following the steps:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/FMInference/FlexGen.git
cd FlexGen
pip3 install -e .

# (Optional) Install openmpi for multi-gpu execution
# sudo apt install openmpi-bin
</code></pre></div></div>

<p>Now you can run the command to download the model and simply test.</p>

<p><code class="language-plaintext highlighter-rouge">python3 -m flexgen.flex_opt --model facebook/opt-1.3b</code></p>

<p>The command <code class="language-plaintext highlighter-rouge">python3 -m flexgen.flex_opt --model facebook/opt-1.3b</code> will be running a Python script that uses the FlexOpt model from Facebook AI Research.</p>

<p>FlexOpt is a neural network-based optimization solver that can be used to solve a wide range of optimization problems. It uses a neural network to learn how to solve optimization problems and can provide efficient solutions to problems with large-scale data.</p>

<p>The command “python3 -m flexgen.flex_opt” is used to run the FlexOpt module in Python 3. The “–model facebook/opt-1.3b” argument specifies the location of the model file to be loaded for use in the optimization process. The model file is located in the “facebook/opt-1.3b” directory, and it contains the trained neural network parameters that are used to solve the optimization problem.</p>

<p>Here is a list of some of models to try</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>opt-1.3b
opt-3b
opt-6b
opt-12b
opt-24b
opt-30b
opt-175b
</code></pre></div></div>
<p>Each model has been trained on a large corpus of optimization problems and can be used to solve a wide range of optimization problems. The models vary in size and complexity, with opt-30b being the largest and most complex model with 175 billion parameters.</p>

<h2 id="step-3-run-the-app">Step 3 Run the app.</h2>

<p><code class="language-plaintext highlighter-rouge">python3 apps/chatbot.py --model facebook/opt-1.3b</code></p>

<h3 id="output">output</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Human: Hello! What can you do?
Assistant: As an AI assistant, I can answer questions and chat with you.
Human: What is the name of the tallest mountain in the world?
Assistant: Everest.
Human: I am planning a trip for our anniversary. What things can we do?
Assistant: Well, there are a number of things you can do for your anniversary. First, you can play cards. Second, you can go for a hike. Third, you can go to a museum.

</code></pre></div></div>

<h2 id="step-4-run-the-app-on-flask">Step 4 Run the app. on flask</h2>

<p>Follow the Flask tutorial as a reference to deploy your chat app</p>

<h1 id="major-advantages-of-chatgpt">Major advantages of ChatGPT</h1>

<ul>
  <li>
    <p>Improved customer service: Companies can use ChatGPT to provide automated chatbot-based customer service, which can help them to quickly and efficiently handle customer inquiries, provide solutions to common issues, and improve the overall customer experience.</p>
  </li>
  <li>
    <p>Enhanced customer engagement: By using ChatGPT, companies can engage with their customers in a more personalized and interactive way, which can help to build customer loyalty and improve brand recognition.</p>
  </li>
  <li>
    <p>Increased efficiency: ChatGPT can help automate a wide range of tasks, including customer service, scheduling, and data entry. By automating these tasks, companies can free up valuable time and resources, which can help to improve overall productivity and efficiency.</p>
  </li>
  <li>
    <p>Cost savings: By automating tasks and improving efficiency, ChatGPT can help companies reduce labor costs and improve overall profitability.</p>
  </li>
  <li>
    <p>Better insights: ChatGPT can help companies analyze customer interactions and conversations to gain insights into customer behavior, preferences, and needs. This information can be used to improve products and services, as well as to develop more targeted marketing campaigns.</p>
  </li>
</ul>

<h1 id="why-gpt-is-different-from-bert">Why GPT is different from BERT</h1>

<p>BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer) are both natural language processing (NLP) models developed by OpenAI and Google, respectively. While they share some similarities, they also have key differences, including:</p>

<ul>
  <li>
    <p>Task type: BERT is primarily used for bidirectional language modeling and pre-training for various downstream NLP tasks, such as question answering and sentiment analysis. GPT, on the other hand, is a generative language model that is primarily used for language generation and text completion tasks.</p>
  </li>
  <li>
    <p>Unidirectional vs bidirectional: BERT is a bidirectional model, meaning it takes into account both the preceding and succeeding words when making predictions, while GPT is a unidirectional model that only looks at the preceding words.</p>
  </li>
  <li>
    <p>Pre-training method: BERT is pre-trained using masked language modeling, where a portion of the input text is masked and the model is trained to predict the masked word. GPT, on the other hand, is pre-trained using a causal language modeling objective, where the model is trained to predict the next word in a sequence.</p>
  </li>
  <li>
    <p>Training data: BERT is pre-trained on a large corpus of unlabeled text from various sources, while GPT is pre-trained on a large corpus of web pages and text from various books.</p>
  </li>
  <li>
    <p>Output type: BERT produces contextualized word embeddings, while GPT produces a sequence of tokens that form a coherent text.</p>
  </li>
  <li>
    <p>Fine-tuning: BERT is typically fine-tuned for specific downstream tasks, while GPT is used as a general-purpose language model for generating text.</p>
  </li>
</ul>

<p>Both BERT and GPT are state-of-the-art NLP models that use the Transformer architecture, they have key differences in task type, pre-training method, training data, output type, and fine-tuning.</p>

<h1 id="conclusion">Conclusion</h1>

<p>A chat application, whether for personal or business use, can offer several advantages, including:</p>

<ul>
  <li>
    <p>Real-time communication: Chat applications enable users to communicate in real-time, making it an efficient and quick way to exchange information and have conversations. This can be particularly useful for businesses where fast communication is often necessary to make quick decisions or respond to customer inquiries.</p>
  </li>
  <li>
    <p>Accessible from anywhere: Chat applications are often cloud-based, which means they can be accessed from anywhere with an internet connection. This makes them particularly useful for remote teams, allowing team members to communicate and collaborate even when they are not in the same physical location.</p>
  </li>
  <li>
    <p>Cost-effective: Chat applications are often free or relatively low-cost, making them an affordable communication tool for both individuals and businesses. This can be particularly helpful for small businesses or startups with limited budgets.</p>
  </li>
  <li>
    <p>Record of communication: Chat applications typically provide a record of past conversations, which can be helpful for future reference or to keep a record of important information. This can be particularly useful in business settings where keeping track of conversations and decisions is crucial.</p>
  </li>
  <li>
    <p>Enhanced productivity: Chat applications can help enhance productivity by reducing the need for face-to-face meetings and phone calls. This can save time and allow team members to focus on their work without being interrupted.</p>
  </li>
  <li>
    <p>Increased engagement: Chat applications can provide a more engaging and interactive way for users to communicate, particularly when used in conjunction with features such as emojis, GIFs, and stickers. This can help build better relationships and improve the overall communication experience.</p>
  </li>
</ul>

<p>In summary, chat applications offer real-time communication, accessibility, cost-effectiveness, a record of communication, enhanced productivity, and increased engagement, making them a valuable tool for personal and business use.</p>



          <!-- Inline code styling -->
          <link href="/assets/css/syntax.css" rel="stylesheet">
          <script src="/assets/scripts/copyCode.js" async></script>

          <!-- Google Ad (responsive rectangle after content) -->
          <section aria-label="Advertisements" class="ads mt-4">
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
            <ins class="adsbygoogle"
                 style="display:block"
                 data-ad-client="ca-pub-2976211678184829"
                 data-ad-slot="7658460605"
                 data-ad-format="auto"
                 data-full-width-responsive="true"></ins>
            <script>
              (adsbygoogle = window.adsbygoogle || []).push({});
            </script>
          </section>

        </article>

        <!-- Post Navigation -->
        <nav class="post-navigation controls__inner mt-5" aria-label="Post navigation">
          <div class="controls__item prev">
            
              <span>Previous</span>
              <a href="/Interview-questions-for-python-programming/" rel="prev">
                Interview questions for python progra...
              </a>
            
          </div>

          <div class="controls__item next">
            
              <span>Next</span>
              <a href="/what-is-svd/" rel="next">
                What is SVD
              </a>
            
          </div>
        </nav>

        <!-- Comments Section -->
        
          <section class="comments mt-5" aria-label="Comments Section">
            
<div id="disqus_thread"></div>
<script>

var disqus_config = function () {
this.page.url = 'http://localhost:4000/How-to-make-chat-GPT-like-application/';
this.page.identifier = 'http://localhost:4000/How-to-make-chat-GPT-like-application/';
};

(function() {
var d = document, s = d.createElement('script');
s.src = 'https://https-py2ai-github-io.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the comments.</noscript>


          </section>
        

      </div>
    </main>

    <footer class="footer">
  <div class="container">
    <nav class="social">
      
      
      
    </nav>
    <span>&copy; 2025 PyShine. All rights reserved.</span>
  </div>
</footer>
<script async src="/assets/js/bundle.js"></script>

<script async>
  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.register('/sw.js').then(function( registration ) {
      console.log('ServiceWorker registration successful with scope: ', registration.scope);
    })
    .catch(function(error) {
      console.log('ServiceWorker registration failed: ', error);
    });
  }
</script>



    <!-- Scripts at bottom for performance -->
    
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>



    <!-- Async Ads script globally -->
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

  </body>
</html>


